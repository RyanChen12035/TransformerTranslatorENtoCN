{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgeikHmiZ9m_"
      },
      "source": [
        "### Ensemble learning\n",
        "\n",
        "Instructor: Nedelina Teneva <br>\n",
        "\n",
        "\n",
        "Citations and Material: <br>\n",
        "\n",
        " - AdaBoost Lecture Notes: https://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/AdaBoost.pdf\n",
        "\n",
        " - Chapter 6, 7: Python Machine Learning 3rd Edition by [Sebastian Raschka](https://sebastianraschka.com), Packt Publishing Ltd. 2019\n",
        "\n",
        " - https://github.com/MIDS-W207/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqhAtMNDZ9nF"
      },
      "source": [
        "##### Question: What methods can we use to construct a set of classifiers that can often have better performance than any of its individual members?\n",
        "- majority vote\n",
        "- k-cross validation\n",
        "- bagging\n",
        "- adaptive boosting (AdaBoost)\n",
        "- holdout method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0m7HYoTZ9nG"
      },
      "source": [
        "### Objectives:\n",
        " - make predictions based on majority voting.\n",
        " - use bagging to reduce overfitting.\n",
        " - use boosting to build powerful models from weak learners that learn from their mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvORLJhtZ9nN"
      },
      "source": [
        "### Learning with ensembles\n",
        " - the idea is to combine different classifiers into a super-classifier whose performance is much better than using each individual classifier alone.\n",
        " - assume that you collect predictions from 10 expert classifiers (e.g., KNN, NB, ...). ensemble methods will allow us to combine their individual predictions to come up with a final prediction that is more accurate and robust.\n",
        " - 3 most commonly used ensembles: majority vote, bagging, and boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_wdUhm-Z9nO"
      },
      "source": [
        "### The majority vote principle\n",
        " - selects the class label that has been predicted by the majority of classifiers (i.e., received more than 50 percent of votes).\n",
        " - the term majority vote is used for a binary class setting.\n",
        " - plurality vote is used for a multiclass setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu_T8cPpZ9nP"
      },
      "source": [
        "### The bagging principle\n",
        " - it's closely related to the majority vote technique.\n",
        " - the difference is that instead of using the same training data to fit the different classifiers in the ensemble, we draw bootstrap (random) samples w/ replacement from the initial training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjv44sJfZ9nQ"
      },
      "source": [
        "### The adaptive boosting (AdaBoost) principle\n",
        "- the ensemble consists of very simple base classifiers (weak learners; think decision tree stump).\n",
        "- focuses on training examples that are hard to clasify, i.e. let the weak learns learn from their mistakes (misclassified training examples) to improve the performance of the ensemble.\n",
        "- in contrast to bagging, the boosting algorithm uses random subsets of training examples drawn from the training dataset **without** replacement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuaBFVbSZ9nR"
      },
      "outputs": [],
      "source": [
        "# standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import operator\n",
        "\n",
        "# visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "%matplotlib inline\n",
        "\n",
        "# pipelines\n",
        "from sklearn.pipeline import _name_estimators\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# data preprocessing, cross-validation, accuracies\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# individual classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# ensemble classifiers\n",
        "##(not that we use a user defined class for MajorityVoting)\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# others\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.base import clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rRPgpaxZ9nT"
      },
      "source": [
        "### Define our owrn Majority vote classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cbH_T3fZ9nT"
      },
      "outputs": [],
      "source": [
        "class MajorityVoteClassifier(BaseEstimator,\n",
        "                             ClassifierMixin):\n",
        "    \"\"\" A majority vote ensemble classifier\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    classifiers : array-like, shape = [n_classifiers]\n",
        "      Different classifiers for the ensemble\n",
        "\n",
        "    vote : str, {'classlabel', 'probability'} (default='classlabel')\n",
        "      If 'classlabel' the prediction is based on the argmax of\n",
        "        class labels. Else if 'probability', the argmax of\n",
        "        the sum of probabilities is used to predict the class label\n",
        "        (recommended for calibrated classifiers).\n",
        "\n",
        "    weights : array-like, shape = [n_classifiers], optional (default=None)\n",
        "      If a list of `int` or `float` values are provided, the classifiers\n",
        "      are weighted by importance; Uses uniform weights if `weights=None`.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
        "\n",
        "        self.classifiers = classifiers\n",
        "        self.named_classifiers = {key: value for key, value\n",
        "                                  in _name_estimators(classifiers)}\n",
        "        self.vote = vote\n",
        "        self.weights = weights\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit classifiers.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
        "            Matrix of training examples.\n",
        "\n",
        "        y : array-like, shape = [n_examples]\n",
        "            Vector of target class labels.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "\n",
        "        \"\"\"\n",
        "        if self.vote not in ('probability', 'classlabel'):\n",
        "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
        "                             \"; got (vote=%r)\"\n",
        "                             % self.vote)\n",
        "\n",
        "        if self.weights and len(self.weights) != len(self.classifiers):\n",
        "            raise ValueError('Number of classifiers and weights must be equal'\n",
        "                             '; got %d weights, %d classifiers'\n",
        "                             % (len(self.weights), len(self.classifiers)))\n",
        "\n",
        "        # Use LabelEncoder to ensure class labels start with 0, which\n",
        "        # is important for np.argmax call in self.predict\n",
        "        self.lablenc_ = LabelEncoder()\n",
        "        self.lablenc_.fit(y)\n",
        "        self.classes_ = self.lablenc_.classes_\n",
        "        self.classifiers_ = []\n",
        "        for clf in self.classifiers:\n",
        "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
        "            self.classifiers_.append(fitted_clf)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict class labels for X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
        "            Matrix of training examples.\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        maj_vote : array-like, shape = [n_examples]\n",
        "            Predicted class labels.\n",
        "\n",
        "        \"\"\"\n",
        "        if self.vote == 'probability':\n",
        "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
        "        else:  # 'classlabel' vote\n",
        "\n",
        "            #  Collect results from clf.predict calls\n",
        "            predictions = np.asarray([clf.predict(X)\n",
        "                                      for clf in self.classifiers_]).T\n",
        "\n",
        "            maj_vote = np.apply_along_axis(\n",
        "                                      lambda x:\n",
        "                                      np.argmax(np.bincount(x,\n",
        "                                                weights=self.weights)),\n",
        "                                      axis=1,\n",
        "                                      arr=predictions)\n",
        "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
        "        return maj_vote\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\" Predict class probabilities for X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix}, shape = [n_examples, n_features]\n",
        "            Training vectors, where n_examples is the number of examples and\n",
        "            n_features is the number of features.\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        avg_proba : array-like, shape = [n_examples, n_classes]\n",
        "            Weighted average probability for each class per example.\n",
        "\n",
        "        \"\"\"\n",
        "        probas = np.asarray([clf.predict_proba(X)\n",
        "                             for clf in self.classifiers_])\n",
        "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
        "        return avg_proba\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
        "        if not deep:\n",
        "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
        "        else:\n",
        "            out = self.named_classifiers.copy()\n",
        "            for name, step in self.named_classifiers.items():\n",
        "                for key, value in step.get_params(deep=True).items():\n",
        "                    out['%s__%s' % (name, key)] = value\n",
        "            return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3aPiSXyZ9nV"
      },
      "source": [
        "### Read and preprocess data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8M-6F7wZ9nV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "205979d1-8d04-4b6b-c58a-8dbccbe04088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of df wine: (178, 14)\n",
            "Class labels: [1 2 3]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class_label  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
              "0            1    14.23        1.71  2.43               15.6        127   \n",
              "1            1    13.20        1.78  2.14               11.2        100   \n",
              "2            1    13.16        2.36  2.67               18.6        101   \n",
              "3            1    14.37        1.95  2.50               16.8        113   \n",
              "4            1    13.24        2.59  2.87               21.0        118   \n",
              "\n",
              "   total_pphenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "0            2.80        3.06                  0.28             2.29   \n",
              "1            2.65        2.76                  0.26             1.28   \n",
              "2            2.80        3.24                  0.30             2.81   \n",
              "3            3.85        3.49                  0.24             2.18   \n",
              "4            2.80        2.69                  0.39             1.82   \n",
              "\n",
              "   color_intensity   hue  OD280/OD315_of_diluted_wines  proline  \n",
              "0             5.64  1.04                          3.92     1065  \n",
              "1             4.38  1.05                          3.40     1050  \n",
              "2             5.68  1.03                          3.17     1185  \n",
              "3             7.80  0.86                          3.45     1480  \n",
              "4             4.32  1.04                          2.93      735  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-124b2203-5922-456c-a043-8b7e95a790b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_label</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_pphenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>OD280/OD315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-124b2203-5922-456c-a043-8b7e95a790b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-124b2203-5922-456c-a043-8b7e95a790b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-124b2203-5922-456c-a043-8b7e95a790b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_init = pd.read_csv('https://archive.ics.uci.edu/'\n",
        "                      'ml/machine-learning-databases/wine/wine.data',\n",
        "                      header=None)\n",
        "\n",
        "df_init.columns = ['class_label', 'alcohol', 'malic_acid', 'ash',\n",
        "              'alcalinity_of_ash', 'magnesium', 'total_pphenols',\n",
        "              'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins',\n",
        "              'color_intensity', 'hue', 'OD280/OD315_of_diluted_wines',\n",
        "              'proline']\n",
        "\n",
        "print('Shape of df wine:', df_init.shape)\n",
        "print('Class labels:', df_init['class_label'].unique())\n",
        "print()\n",
        "df_init.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stplunvXZ9nW"
      },
      "source": [
        "**Recode class labels**: easier to iterate functions that iterate through labels (index starts at 0 in Python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb2QL09LZ9nW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e7dfcc-15a7-4cf2-bd53-7007b626d8c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels: [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "class_mapping = {label: idx for idx, label in enumerate(np.unique(df_init.class_label))}\n",
        "class_mapping\n",
        "\n",
        "df_init['class_label'] = df_init.class_label.map(class_mapping)\n",
        "print('Class labels:', df_init.class_label.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJRp4YelZ9nX"
      },
      "source": [
        "**Data subseting**: This example uses class labels 0 and 1 (I want to focus on a majority vote example, so the outcome should be binary), and 2 features ['alcohol', 'OD280/OD315_of_diluted_wines' (protein content)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P8LlJdGZ9nX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "541f6222-3aa8-42fd-d941-a3c0142e88ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class labels: [0 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   class_label  alcohol  OD280/OD315_of_diluted_wines\n",
              "0            0    14.23                          3.92\n",
              "1            0    13.20                          3.40\n",
              "2            0    13.16                          3.17\n",
              "3            0    14.37                          3.45\n",
              "4            0    13.24                          2.93"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f53fd19c-2e98-4055-b10e-1f9556d3bd4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_label</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>OD280/OD315_of_diluted_wines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14.23</td>\n",
              "      <td>3.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>13.20</td>\n",
              "      <td>3.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>13.16</td>\n",
              "      <td>3.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>14.37</td>\n",
              "      <td>3.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>13.24</td>\n",
              "      <td>2.93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f53fd19c-2e98-4055-b10e-1f9556d3bd4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f53fd19c-2e98-4055-b10e-1f9556d3bd4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f53fd19c-2e98-4055-b10e-1f9556d3bd4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# select only labels 0 and 1\n",
        "df = df_init[df_init.class_label !=2]\n",
        "\n",
        "# select only 4 features\n",
        "labels = ['class_label']\n",
        "features = ['alcohol', 'OD280/OD315_of_diluted_wines']\n",
        "df = df[labels+features]\n",
        "print('Class labels:', df.class_label.unique())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStj7Q-aZ9nY"
      },
      "source": [
        "**Train/test splits**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPtVknVMZ9nY"
      },
      "outputs": [],
      "source": [
        "# create X and y arrays\n",
        "X = np.array(df.iloc[:, 1:])\n",
        "y = np.array(df.iloc[:, 0])\n",
        "\n",
        "\n",
        "# create samples\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPsspR4IZ9nY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23298562-fd57-4542-a8fa-d49ec70540a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_train:  (104, 2) \n",
            "Shape X_test:  (26, 2) \n",
            "Shape y_train:  (104,) \n",
            "Shape y_test: (26,)\n"
          ]
        }
      ],
      "source": [
        "print('Shape X_train: ', X_train.shape, '\\nShape X_test: ', X_test.shape,\n",
        "      '\\nShape y_train: ', y_train.shape, '\\nShape y_test:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxpnZq2vZ9nZ"
      },
      "source": [
        "### **1. Ensemble learning - majority vote**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLAFd8pXZ9na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35cbd0f-0a08-41c0-e548-833a2bc8ea82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-fold cross validation (CV):\n",
            "\n",
            "CV accuracy: 0.94 (+/- 0.06) [Decision tree]\n",
            "CV accuracy: 0.95 (+/- 0.06) [KNN]\n"
          ]
        }
      ],
      "source": [
        "clf1 = DecisionTreeClassifier(max_depth=2,\n",
        "                              criterion='entropy')\n",
        "\n",
        "clf2 = KNeighborsClassifier(n_neighbors=5,\n",
        "                            p=2,\n",
        "                            metric='minkowski')\n",
        "\n",
        "# the KNN classifier is not scale-invariant whereas the decission tree classifier is.\n",
        "# remember it's a good habit to work with standardized features, so let's use a Pipeline (https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to standardize the features for KNN\n",
        "# the StandardScaller method in sklearn.preprocessing module does this for us\n",
        "clf2_pipeline = Pipeline([['sc', StandardScaler()],\n",
        "                  ['clf', clf2]])\n",
        "\n",
        "# define classifier labels\n",
        "clf_labels = ['Decision tree', 'KNN']\n",
        "\n",
        "# evaluate the model performance for each classifier using 10-fold cross validation on the training data\n",
        "# note that with the 10-fold validation we don't try to find the optimal combination of hyperparameter values (i.e., use the GridSearchCV() method from sklearn.model_selection module)\n",
        "# instead, we want to fine-tune the performance given a single set of hyperparameter values\n",
        "print('10-fold cross validation (CV):\\n')\n",
        "for clf, label in zip([clf1, clf2_pipeline], clf_labels):\n",
        "    scores = cross_val_score(estimator=clf,\n",
        "                             X=X_train,\n",
        "                             y=y_train,\n",
        "                             cv=10,\n",
        "                             n_jobs=1) # n_jobs = the number of CPUs to use, set to -1 to use all\n",
        "    print(\"CV accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
        "          % (scores.mean(), scores.std(), label)) # cross_val_score() returns stats(e.g., mean and variance) for accuracy scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PctcJ290Z9na"
      },
      "source": [
        "The output shows that the CV accuracy of the individual classifiers are similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4rY2scfZ9na"
      },
      "source": [
        "Combine the individual classifiers for majority rule voting. Use the user-defined MajorityVoteClassifier class (see above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5dW8LKZ9nb"
      },
      "outputs": [],
      "source": [
        "mv_clf = MajorityVoteClassifier(classifiers=[clf1, clf2_pipeline])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMODbpV6Z9nb"
      },
      "source": [
        "Evaluate performance using 10-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_36_0zRZ9nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcbaa99-3228-414e-bdc0-6ed1e25021ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV accuracy: 0.94 (+/- 0.06) [Decision tree]\n",
            "CV accuracy: 0.95 (+/- 0.06) [KNN]\n",
            "CV accuracy: 0.94 (+/- 0.06) [Majority voting]\n"
          ]
        }
      ],
      "source": [
        "clf_labels += ['Majority voting']\n",
        "all_clf = [clf1, clf2_pipeline, mv_clf]\n",
        "\n",
        "for clf, label in zip(all_clf, clf_labels):\n",
        "    scores = cross_val_score(estimator=clf,\n",
        "                             X=X_train,\n",
        "                             y=y_train,\n",
        "                             cv=10,\n",
        "                             n_jobs=1)\n",
        "    print(\"CV accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
        "          % (scores.mean(), scores.std(), label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78aHSgIYZ9nc"
      },
      "source": [
        "The performance of the majority vote classifier didn't seem to have improved over the individual classifiers in the 10-fold cross validation evaluation.\n",
        "\n",
        "Hint: trying changing the features to ['alcohol', 'ash', 'malic_acid] and size of test sample to 0.35."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d3VXtktZ9nd"
      },
      "source": [
        "\n",
        "### **2. Ensemble learning - bagging**\n",
        "\n",
        "Let's use an already implemented version in scikit-learn this time, available in the ensemble module.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B711tEoZ9nd"
      },
      "source": [
        "#### Train an unpruned decision tree\n",
        "\n",
        "Question: What is an unpruned decission tree?\n",
        "\n",
        "Answer: The unpruned trees are larger than pruned trees. Nodes are expanded until all leaves are pure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g1zHPS8Z9ne"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(criterion='entropy',\n",
        "                              max_depth=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKzgyCQXZ9ne"
      },
      "source": [
        "####  Use bagging for classification\n",
        "\n",
        "Use the unpruned decision tree as the base clasifier, and create an ensemble of 500 decision trees fit on different bootsrap samples (w/ replacement) of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N253ZUhUZ9nf"
      },
      "outputs": [],
      "source": [
        "bag = BaggingClassifier(base_estimator=tree,\n",
        "                        n_estimators=500,\n",
        "                        n_jobs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5-TAfeDZ9nf"
      },
      "source": [
        "#### Evaluate performance using accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDO4OK_1Z9ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a416c05-a3c1-4da4-8ea9-236a591a7d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree train/test accuracies 1.000/0.846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging train/test accuracies 1.000/0.885\n"
          ]
        }
      ],
      "source": [
        "# performance of the base tree alone\n",
        "tree = tree.fit(X_train, y_train)\n",
        "y_train_pred = tree.predict(X_train)\n",
        "y_test_pred = tree.predict(X_test)\n",
        "\n",
        "tree_train = accuracy_score(y_train, y_train_pred)\n",
        "tree_test = accuracy_score(y_test, y_test_pred)\n",
        "print('Decision tree train/test accuracies %.3f/%.3f'\n",
        "      % (tree_train, tree_test))\n",
        "\n",
        "# performance of bagging\n",
        "bag = bag.fit(X_train, y_train)\n",
        "y_train_pred = bag.predict(X_train)\n",
        "y_test_pred = bag.predict(X_test)\n",
        "\n",
        "bag_train = accuracy_score(y_train, y_train_pred)\n",
        "bag_test = accuracy_score(y_test, y_test_pred)\n",
        "print('Bagging train/test accuracies %.3f/%.3f'\n",
        "      % (bag_train, bag_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3LVCGhKZ9ng"
      },
      "source": [
        "The unpruned decission tree predicts all class labels in the training data set correctly, but fails to generalize. The much lower accuracy on the test sample indicates high variance (overfitting) of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjD8BKLnZ9nh"
      },
      "source": [
        "The bagging classifier has a slightly better performance on the test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB1pyvGJZ9nh"
      },
      "source": [
        "---\n",
        "### **3. Ensemble learning - AdaBoost**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Uik_o-Z9nh"
      },
      "source": [
        "Algorithm idea (4 key steps):<br>\n",
        " 1. Draw a random sample of training examples, 𝑑𝑑1, without\n",
        "replacement from the training dataset, D, to train a weak learner, 𝐶𝐶1.\n",
        " 2. Draw a second random sample of training examples, 𝑑𝑑2, without replacement from the\n",
        "training dataset and add 50 percent of the examples that were previously\n",
        "misclassified to train a weak learner, 𝐶𝐶2.\n",
        " 3. Find the training examples, 𝑑𝑑3, in the training dataset, D, which 𝐶𝐶1 and 𝐶𝐶2\n",
        "disagree upon, to train a third weak learner, 𝐶𝐶3.\n",
        " 4. Combine the weak learners 𝐶𝐶1, 𝐶𝐶2, and 𝐶𝐶3 via majority voting.\n",
        "\n",
        "Freund & Schapire's AdaBoost paper: https://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf\n",
        "https://cseweb.ucsd.edu/~yfreund/papers/BoostByMajority.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpNVVCYsZ9ni"
      },
      "source": [
        "#### Train a stump decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S39UHEBrZ9ni"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(criterion='entropy',\n",
        "                              max_depth=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pZVNhS9Z9ni"
      },
      "source": [
        "#### Use AdaBoost for classification\n",
        "\n",
        "Use the unpruned decision tree as the base clasifier, and create an ensemble of 500 decision trees fit on different bootsrap samples (w/ replacement) of the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_38NqWp6Z9nl"
      },
      "outputs": [],
      "source": [
        "ada = AdaBoostClassifier(base_estimator=tree,\n",
        "                         n_estimators=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBpnIEy3Z9nl"
      },
      "source": [
        "#### Evaluate performance using accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgpPhYM3Z9nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5975b7-b82d-4212-a377-976ab2f93502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree train/test accuracies 0.952/0.846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost train/test accuracies 1.000/0.885\n"
          ]
        }
      ],
      "source": [
        "tree = tree.fit(X_train, y_train)\n",
        "y_train_pred = tree.predict(X_train)\n",
        "y_test_pred = tree.predict(X_test)\n",
        "\n",
        "tree_train = accuracy_score(y_train, y_train_pred)\n",
        "tree_test = accuracy_score(y_test, y_test_pred)\n",
        "print('Decision tree train/test accuracies %.3f/%.3f'\n",
        "      % (tree_train, tree_test))\n",
        "\n",
        "ada = ada.fit(X_train, y_train)\n",
        "y_train_pred = ada.predict(X_train)\n",
        "y_test_pred = ada.predict(X_test)\n",
        "\n",
        "ada_train = accuracy_score(y_train, y_train_pred)\n",
        "ada_test = accuracy_score(y_test, y_test_pred)\n",
        "print('AdaBoost train/test accuracies %.3f/%.3f'\n",
        "      % (ada_train, ada_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pytj6J5Z9nm"
      },
      "source": [
        "The AdaBoost ensemble predicts all class labels in the training data correctly.\n",
        "\n",
        "It also improves the prediction performance on the test data compared to the decision tree stump alone."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}