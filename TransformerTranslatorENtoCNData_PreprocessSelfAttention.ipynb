{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Transformer implementation by Tensorflow and make it as a ZN to EN translator\n",
        "#### 8/3 go through the code and debug it. Need to review how to do it.\n",
        "#### https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#top\n"
      ],
      "metadata": {
        "id": "yUuYU_Y9UiXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "1Y_asZWyUt9z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0\n",
        "clear_output()\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_J5dQqUU1Z3",
        "outputId": "81549e67-9b97-40c4-dbce-9aba4fbe04c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=\"error\")\n",
        "\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "TT8-7beEU_N9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up directory\n",
        "output_dir = \"nmt\"\n",
        "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
        "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(output_dir, 'logs')\n",
        "download_dir = \"tensorflow-datasets/downloads\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)"
      ],
      "metadata": {
        "id": "E-80roiwVJrF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check out the data source we have\n",
        "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
        "pprint(tmp_builder.subsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpRjAnLVRPU",
        "outputId": "d6624635-4425-4fe9-d6fd-829f531935fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Split('train'): ['newscommentary_v14',\n",
            "                  'wikititles_v1',\n",
            "                  'uncorpus_v1',\n",
            "                  'casia2015',\n",
            "                  'casict2011',\n",
            "                  'casict2015',\n",
            "                  'datum2015',\n",
            "                  'datum2017',\n",
            "                  'neu2017'],\n",
            " Split('validation'): ['newstest2018']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download data by tfds.builder\n",
        "config = tfds.translate.wmt.WmtConfig(\n",
        "  version=tfds.core.Version('0.0.3'),\n",
        "  language_pair=(\"zh\", \"en\"),\n",
        "  subsets={\n",
        "    tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
        "  }\n",
        ")\n",
        "builder = tfds.builder(\"wmt_translate\", config=config)\n",
        "builder.download_and_prepare(download_dir=download_dir)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "hJA02j6UVpRf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set builder to dataset(data pipeline type), split it into training, validation, testing\n",
        "examples = builder.as_dataset(split=['train[:20%]','train[20%:21%]','train[21%:]'], as_supervised=True)"
      ],
      "metadata": {
        "id": "NY3PQntvW6Cu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#leave the testing examples this time.\n",
        "train_examples, val_examples, _ = examples\n",
        "print(train_examples)\n",
        "print(val_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7F-GtSBcmtG",
        "outputId": "7568af19-1d33-4a78-e444-7ff8c72fd87f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for en, zh in train_examples.take(3):\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX4ve2FRcush",
        "outputId": "5ed4ad7d-e0b2-4dbf-adbf-4b7b4d9a9971"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word \\xe2\\x80\\x9cliberal\\xe2\\x80\\x9d \\xe2\\x80\\x93 a champion of the cause of individual freedom.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe4\\xba\\x8b\\xe5\\xae\\x9e\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe5\\xbe\\xb7\\xe5\\x9b\\xbd\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xb1\\x80\\xe5\\x8a\\xbf\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe8\\xbf\\x87\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe7\\xac\\xa6\\xe5\\x90\\x88\\xe7\\xbe\\x8e\\xe5\\x9b\\xbd\\xe6\\x89\\x80\\xe8\\xb0\\x93\\xe2\\x80\\x9c\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe2\\x80\\x9d\\xe5\\xae\\x9a\\xe4\\xb9\\x89\\xe7\\x9a\\x84\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe7\\x9a\\x84\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe5\\x85\\x9a\\xe6\\xb4\\xbe\\xef\\xbc\\x8c\\xe4\\xb9\\x9f\\xe5\\xb0\\xb1\\xe6\\x98\\xaf\\xe4\\xb8\\xaa\\xe4\\xba\\xba\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe4\\xba\\x8b\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x80\\xa1\\xe5\\xaf\\xbc\\xe8\\x80\\x85\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe5\\xbf\\x85\\xe9\\xa1\\xbb\\xe4\\xbb\\x98\\xe5\\x87\\xba\\xe5\\xb7\\xa8\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\x92\\x8c\\xe5\\x9f\\xba\\xe7\\xa1\\x80\\xe8\\xae\\xbe\\xe6\\x96\\xbd\\xe6\\x8a\\x95\\xe8\\xb5\\x84\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\xae\\x8c\\xe6\\x88\\x90\\xe5\\x90\\x91\\xe5\\x8f\\xaf\\xe5\\x86\\x8d\\xe7\\x94\\x9f\\xe8\\x83\\xbd\\xe6\\xba\\x90\\xe7\\x9a\\x84\\xe8\\xbf\\x87\\xe6\\xb8\\xa1\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_examples = []\n",
        "num_samples = 10\n",
        "\n",
        "for en_t, zh_t in train_examples.take(num_samples):\n",
        "  en = en_t.numpy().decode(\"utf-8\")\n",
        "  zh = zh_t.numpy().decode(\"utf-8\")\n",
        "\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "\n",
        "  # 之後用來簡單評估模型的訓練情況\n",
        "  sample_examples.append((en, zh))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwRnP2H6cxDB",
        "outputId": "97759dc1-505e-4078-88a0-9aadb10c53c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fear is real and visceral, and politicians ignore it at their peril.\n",
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "----------\n",
            "In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word “liberal” – a champion of the cause of individual freedom.\n",
            "事实上，德国政治局势需要的不过是一个符合美国所谓“自由”定义的真正的自由党派，也就是个人自由事业的倡导者。\n",
            "----------\n",
            "Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.\n",
            "必须付出巨大的努力和基础设施投资才能完成向可再生能源的过渡。\n",
            "----------\n",
            "In this sense, it is critical to recognize the fundamental difference between “urban villages” and their rural counterparts.\n",
            "在这方面，关键在于认识到“城市村落”和农村村落之间的根本区别。\n",
            "----------\n",
            "A strong European voice, such as Nicolas Sarkozy’s during the French presidency of the EU, may make a difference, but only for six months, and at the cost of reinforcing other European countries’ nationalist feelings in reaction to the expression of “Gallic pride.”\n",
            "法国担任轮值主席国期间尼古拉·萨科奇统一的欧洲声音可能让人耳目一新，但这种声音却只持续了短短六个月，而且付出了让其他欧洲国家在面对“高卢人的骄傲”时民族主义情感进一步被激发的代价。\n",
            "----------\n",
            "Most of Japan’s bondholders are nationals (if not the central bank) and have an interest in political stability.\n",
            "日本债券持有人大多为本国国民（甚至中央银行 ） ， 政治稳定符合他们的利益。\n",
            "----------\n",
            "Paul Romer, one of the originators of new growth theory, has accused some leading names, including the Nobel laureate Robert Lucas, of what he calls “mathiness” – using math to obfuscate rather than clarify.\n",
            "新增长理论创始人之一的保罗·罗默（Paul Romer）也批评一些著名经济学家，包括诺贝尔奖获得者罗伯特·卢卡斯（Robert Lucas）在内，说他们“数学性 ” （ 罗默的用语）太重，结果是让问题变得更加模糊而不是更加清晰。\n",
            "----------\n",
            "It is, in fact, a capsule depiction of the United States Federal Reserve and the European Central Bank.\n",
            "事实上，这就是对美联储和欧洲央行的简略描述。\n",
            "----------\n",
            "Given these variables, the degree to which migration is affected by asylum-seekers will not be easy to predict or control.\n",
            "考虑到这些变量，移民受寻求庇护者的影响程度很难预测或控制。\n",
            "----------\n",
            "WASHINGTON, DC – In the 2016 American presidential election, Hillary Clinton and Donald Trump agreed that the US economy is suffering from dilapidated infrastructure, and both called for greater investment in renovating and upgrading the country’s public capital stock.\n",
            "华盛顿—在2016年美国总统选举中，希拉里·克林顿和唐纳德·特朗普都认为美国经济饱受基础设施陈旧的拖累，两人都要求加大投资用于修缮和升级美国公共资本存量。\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create own eng dictionary\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
        "  print(f\"載入已建立的字典： {en_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples),\n",
        "      target_vocab_size=2**13) # 有需要可以調整字典大小\n",
        "\n",
        "  # 將字典檔案存下以方便下次 warmstart\n",
        "  subword_encoder_en.save_to_file(en_vocab_file)\n",
        "\n",
        "\n",
        "print(f\"字典大小：{subword_encoder_en.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_en.subwords[:10]}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_h82Jm4eFD_",
        "outputId": "78497f03-f885-40f6-d102-c9e4e3cb2aa9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：8113\n",
            "前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
            "\n",
            "CPU times: user 1min 30s, sys: 3.72 s, total: 1min 33s\n",
            "Wall time: 1min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5fvarXdi4xc",
        "outputId": "ca6b9d61-5a36-4882-bca3-16399524510e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3461, 7889, 9, 3502, 4379, 1134, 7903]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
        "print(\"-\" * 15)\n",
        "for idx in indices:\n",
        "  subword = subword_encoder_en.decode([idx])\n",
        "  print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvXXZn5sjHHs",
        "outputId": "49e6d875-1a21-4691-8204-518f21fb3726"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index     Subword\n",
            "---------------\n",
            " 3461     Taiwan\n",
            " 7889      \n",
            "    9     is \n",
            " 3502     bea\n",
            " 4379     uti\n",
            " 1134     ful\n",
            " 7903     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "try:\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
        "  print(f\"載入已建立的字典： {zh_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples),\n",
        "      target_vocab_size=2**13, # 有需要可以調整字典大小\n",
        "      max_subword_length=1) # 每一個中文字就是字典裡的一個單位\n",
        "\n",
        "  # 將字典檔案存下以方便下次 warmstart\n",
        "  subword_encoder_zh.save_to_file(zh_vocab_file)\n",
        "\n",
        "print(f\"字典大小：{subword_encoder_zh.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kHMkfIWjLZh",
        "outputId": "0c295f24-f714-4a8e-c9e5-2ab3068c6c08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：4205\n",
            "前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n",
            "\n",
            "CPU times: user 7min 2s, sys: 2.82 s, total: 7min 5s\n",
            "Wall time: 7min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = sample_examples[0][1]\n",
        "indices = subword_encoder_zh.encode(sample_string)\n",
        "print(sample_string)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzEX-WxGjVqY",
        "outputId": "19cf17c1-e97a-46fb-9ea6-9767ac7beac0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "[10, 151, 574, 1298, 6, 374, 55, 29, 193, 5, 1, 3, 3981, 931, 431, 125, 1, 17, 124, 33, 20, 97, 1089, 1247, 861, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en = \"The eurozone’s collapse forces a major realignment of European politics.\"\n",
        "zh = \"欧元区的瓦解强迫欧洲政治进行一次重大改组。\"\n",
        "\n",
        "# 將文字轉成為 subword indices\n",
        "en_indices = subword_encoder_en.encode(en)\n",
        "zh_indices = subword_encoder_zh.encode(zh)\n",
        "\n",
        "print(\"[英中原文]（轉換前）\")\n",
        "print(en)\n",
        "print(zh)\n",
        "print()\n",
        "print('-' * 20)\n",
        "print()\n",
        "print(\"[英中序列]（轉換後）\")\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUuy26KRjajN",
        "outputId": "0d158f70-ce74-4955-839f-26135063a349"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[英中原文]（轉換前）\n",
            "The eurozone’s collapse forces a major realignment of European politics.\n",
            "欧元区的瓦解强迫欧洲政治进行一次重大改组。\n",
            "\n",
            "--------------------\n",
            "\n",
            "[英中序列]（轉換後）\n",
            "[16, 900, 11, 6, 1527, 874, 8, 230, 2259, 2728, 239, 3, 89, 1236, 7903]\n",
            "[44, 202, 168, 1, 852, 201, 231, 592, 44, 87, 17, 124, 106, 38, 7, 279, 86, 18, 212, 265, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(en_t, zh_t):\n",
        "  # 因為字典的索引從 0 開始，\n",
        "  # 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值\n",
        "  # 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值\n",
        "  en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(\n",
        "      en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
        "  # 同理，不過是使用中文字典的最後一個索引 + 1\n",
        "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
        "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
        "\n",
        "  return en_indices, zh_indices"
      ],
      "metadata": {
        "id": "9UtvlUStk7hp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_t, zh_t = next(iter(train_examples))\n",
        "en_indices, zh_indices = encode(en_t, zh_t)\n",
        "print('英文 BOS 的 index：', subword_encoder_en.vocab_size)\n",
        "print('英文 EOS 的 index：', subword_encoder_en.vocab_size + 1)\n",
        "print('中文 BOS 的 index：', subword_encoder_zh.vocab_size)\n",
        "print('中文 EOS 的 index：', subword_encoder_zh.vocab_size + 1)\n",
        "\n",
        "print('\\n輸入為 2 個 Tensors：')\n",
        "pprint((en_t, zh_t))\n",
        "print('-' * 15)\n",
        "print('輸出為 2 個索引序列：')\n",
        "pprint((en_indices, zh_indices))"
      ],
      "metadata": {
        "id": "4eQiwP3WlCmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207a571d-db14-48a7-a597-4adc74a9edaa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文 BOS 的 index： 8113\n",
            "英文 EOS 的 index： 8114\n",
            "中文 BOS 的 index： 4205\n",
            "中文 EOS 的 index： 4206\n",
            "\n",
            "輸入為 2 個 Tensors：\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'The fear is real and visceral, and politicians ignore it at their peril.'>,\n",
            " <tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82'>)\n",
            "---------------\n",
            "輸出為 2 個索引序列：\n",
            "([8113,\n",
            "  16,\n",
            "  1284,\n",
            "  9,\n",
            "  243,\n",
            "  5,\n",
            "  1275,\n",
            "  1756,\n",
            "  156,\n",
            "  1,\n",
            "  5,\n",
            "  1016,\n",
            "  5566,\n",
            "  21,\n",
            "  38,\n",
            "  33,\n",
            "  2982,\n",
            "  7965,\n",
            "  7903,\n",
            "  8114],\n",
            " [4205,\n",
            "  10,\n",
            "  151,\n",
            "  574,\n",
            "  1298,\n",
            "  6,\n",
            "  374,\n",
            "  55,\n",
            "  29,\n",
            "  193,\n",
            "  5,\n",
            "  1,\n",
            "  3,\n",
            "  3981,\n",
            "  931,\n",
            "  431,\n",
            "  125,\n",
            "  1,\n",
            "  17,\n",
            "  124,\n",
            "  33,\n",
            "  20,\n",
            "  97,\n",
            "  1089,\n",
            "  1247,\n",
            "  861,\n",
            "  3,\n",
            "  4206])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_encode(en_t, zh_t):\n",
        "  # 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors\n",
        "  # 要到 `tf.py_funtion` 裡頭才是\n",
        "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
        "  return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，\n",
        "# 我們會從頭建立一個正式的 `train_dataset`\n",
        "tmp_dataset = train_examples.map(tf_encode)\n",
        "en_indices, zh_indices = next(iter(tmp_dataset))\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ishJYlKVljve",
        "outputId": "9470fb2c-fb37-467e-e374-969ca3502403"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[8113   16 1284    9  243    5 1275 1756  156    1    5 1016 5566   21\n",
            "   38   33 2982 7965 7903 8114], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[4205   10  151  574 1298    6  374   55   29  193    5    1    3 3981\n",
            "  931  431  125    1   17  124   33   20   97 1089 1247  861    3 4206], shape=(28,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
        "  # en, zh 分別代表英文與中文的索引序列\n",
        "  return tf.logical_and(tf.size(en) <= max_length,\n",
        "                        tf.size(zh) <= max_length)\n",
        "\n",
        "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
        "train_dataset = tmp_dataset.filter(filter_max_length)"
      ],
      "metadata": {
        "id": "jHVJ4aUymTOs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 因為我們數據量小可以這樣 count\n",
        "num_examples = 0\n",
        "for en_indices, zh_indices in train_dataset:\n",
        "  cond1 = len(en_indices) <= MAX_LENGTH\n",
        "  cond2 = len(zh_indices) <= MAX_LENGTH\n",
        "  assert cond1 and cond2\n",
        "  num_examples += 1\n",
        "\n",
        "print(f\"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens\")\n",
        "print(f\"訓練資料集裡總共有 {num_examples} 筆數據\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0foVyEemh8B",
        "outputId": "98079fe4-662d-42d3-90b2-63b0cb3d4543"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "所有英文與中文序列長度都不超過 40 個 tokens\n",
            "訓練資料集裡總共有 29784 筆數據\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
        "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "en_batch, zh_batch = next(iter(tmp_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svth2q8Km5ZY",
        "outputId": "b500848f-8b94-4234-d303-b934586d7df7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113   16 1284 ...    0    0    0]\n",
            " [8113   44  369 ...    0    0    0]\n",
            " [8113 1894 1302 ...    0    0    0]\n",
            " ...\n",
            " [8113 1668    1 ... 4024 7903 8114]\n",
            " [8113 5751 1538 ...    0    0    0]\n",
            " [8113 1809 5706 ...    0    0    0]], shape=(64, 71), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   10  151 ...    0    0    0]\n",
            " [4205  109   55 ...    0    0    0]\n",
            " [4205  206  275 ...    0    0    0]\n",
            " ...\n",
            " [4205   73   76 ...    0    0    0]\n",
            " [4205    5  115 ...    0    0    0]\n",
            " [4205    9  270 ...    0    0    0]], shape=(64, 116), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 15000\n",
        "\n",
        "# 訓練集\n",
        "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
        "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
        "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
        "                 .cache() # 加快讀取數據\n",
        "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
        "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
        "                               padded_shapes=([-1], [-1]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "# 驗證集\n",
        "val_dataset = (val_examples\n",
        "               .map(tf_encode)\n",
        "               .filter(filter_max_length)\n",
        "               .padded_batch(BATCH_SIZE,\n",
        "                             padded_shapes=([-1], [-1])))"
      ],
      "metadata": {
        "id": "i2uYQzDvnDVj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_batch, zh_batch = next(iter(train_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME__uxI_nHvb",
        "outputId": "95971083-5a68-4ce5-d798-61ea881e0fef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113 7050  803 ...    0    0    0]\n",
            " [8113  258    1 ...    0    0    0]\n",
            " [8113  125 3621 ...    0    0    0]\n",
            " ...\n",
            " [8113   16 7928 ...    0    0    0]\n",
            " [8113 3682 7902 ...    0    0    0]\n",
            " [8113   87    9 ...    0    0    0]], shape=(128, 36), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   11   54 ...    0    0    0]\n",
            " [4205   76  130 ...    0    0    0]\n",
            " [4205   65  134 ...    0    0    0]\n",
            " ...\n",
            " [4205   73   76 ...    0    0    0]\n",
            " [4205  173  339 ...    0    0    0]\n",
            " [4205   73   76 ...    0    0    0]], shape=(128, 40), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_examples = [\n",
        "    (\"It is important.\", \"这很重要。\"),\n",
        "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
        "]\n",
        "pprint(demo_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GY4jTq0nWBd",
        "outputId": "aab8cb7d-957a-43d8-f196-6320dd7df988"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('It is important.', '这很重要。'),\n",
            " ('The numbers speak for themselves.', '数字证明了一切。')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
        "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
        "))\n",
        "\n",
        "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
        "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
        "demo_dataset = demo_examples.map(tf_encode)\\\n",
        "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
        "\n",
        "# 取出這個 demo dataset 裡唯一一個 batch\n",
        "inp, tar = next(iter(demo_dataset))\n",
        "print('inp:', inp)\n",
        "print('' * 10)\n",
        "print('tar:', tar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrdNMrOKnc9J",
        "outputId": "481df591-ab41-49f0-929a-59f7aa6ce443"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "\n",
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
        "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
        "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
        "d_model = 4\n",
        "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
        "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
        "\n",
        "emb_inp = embedding_layer_en(inp)\n",
        "emb_tar = embedding_layer_zh(tar)\n",
        "emb_inp, emb_tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g19vVT_Lnd5V",
        "outputId": "e08f4005-0a8e-4313-b008-600d5b5bbebb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              " array([[[-0.00199723,  0.00680826,  0.01488414,  0.0447016 ],\n",
              "         [-0.00579196,  0.03432131, -0.01127356, -0.01371051],\n",
              "         [-0.01317365, -0.01123785, -0.02717954, -0.00209483],\n",
              "         [-0.02212193,  0.03168967,  0.00634627,  0.02523938],\n",
              "         [ 0.01858512,  0.01957585, -0.01394806, -0.0028327 ],\n",
              "         [-0.04932721,  0.02893816, -0.01498246, -0.04549257],\n",
              "         [-0.0367211 , -0.03001974, -0.00548104,  0.01677741],\n",
              "         [-0.0367211 , -0.03001974, -0.00548104,  0.01677741]],\n",
              " \n",
              "        [[-0.00199723,  0.00680826,  0.01488414,  0.0447016 ],\n",
              "         [-0.01424537,  0.04252477, -0.04461938,  0.03427823],\n",
              "         [ 0.00012944, -0.03766169,  0.01255461,  0.01765216],\n",
              "         [-0.02862835,  0.04016503,  0.02635698,  0.04124168],\n",
              "         [-0.03105009,  0.04924557, -0.0452176 ,  0.02693221],\n",
              "         [ 0.01053728,  0.00994729, -0.00897037,  0.02762072],\n",
              "         [ 0.01858512,  0.01957585, -0.01394806, -0.0028327 ],\n",
              "         [-0.04932721,  0.02893816, -0.01498246, -0.04549257]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
              " array([[[-0.03373228, -0.03886728, -0.04052199, -0.00955547],\n",
              "         [ 0.00309727,  0.01263506, -0.01082643,  0.03708297],\n",
              "         [ 0.00894903, -0.04663102, -0.00850056, -0.03314763],\n",
              "         [-0.02755705,  0.00652428,  0.00884439,  0.00857745],\n",
              "         [-0.00100239, -0.00545176, -0.0256992 ,  0.00959864],\n",
              "         [ 0.03556677, -0.0241802 , -0.00550144,  0.01574165],\n",
              "         [-0.01121855,  0.01493908, -0.03981457,  0.04909338],\n",
              "         [-0.02114817,  0.04496567, -0.00567023,  0.03220527],\n",
              "         [-0.02114817,  0.04496567, -0.00567023,  0.03220527],\n",
              "         [-0.02114817,  0.04496567, -0.00567023,  0.03220527]],\n",
              " \n",
              "        [[-0.03373228, -0.03886728, -0.04052199, -0.00955547],\n",
              "         [-0.01923163,  0.01217077,  0.02731622, -0.02458288],\n",
              "         [ 0.00741919,  0.01664327, -0.01079142, -0.00200734],\n",
              "         [-0.01870476, -0.02902025, -0.00527334,  0.0432407 ],\n",
              "         [-0.0083392 ,  0.03258276,  0.04262007,  0.01954139],\n",
              "         [ 0.00024738,  0.01509402, -0.00632627, -0.00339556],\n",
              "         [-0.0274243 ,  0.01855371,  0.00460332, -0.04774611],\n",
              "         [-0.0433907 ,  0.02001016,  0.02617599, -0.00279851],\n",
              "         [ 0.03556677, -0.0241802 , -0.00550144,  0.01574165],\n",
              "         [-0.01121855,  0.01493908, -0.03981457,  0.04909338]]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "J8abWyXMiosN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "inp_mask = create_padding_mask(inp)\n",
        "inp_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQhBT7xobi1",
        "outputId": "edf251cd-3ab7-40e8-de10-8e0aeb056e11"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 1, 8), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tf.squeeze(inp_mask):\", tf.squeeze(inp_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlbEMTQxo0zn",
        "outputId": "5bb070fa-0ac2-4baa-af1e-9ccec56d15ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "tf.squeeze(inp_mask): tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
        "tf.random.set_seed(9527)\n",
        "\n",
        "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
        "q = emb_inp\n",
        "k = emb_inp\n",
        "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
        "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEU9Rv6Uo6kD",
        "outputId": "3ee3f7ea-4e50-4524-eaaa-db9b23225cb6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.]],\n",
              "\n",
              "       [[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "  # 將 `q`、 `k` 做點積再 scale\n",
        "  # 2D np.dot = tf.matmul\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
        "\n",
        "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "  # in this case, scaled_attention_logits a tensor with size of (2,8,8) and mask size of (2,1,8), the mask would atuo expand to (2,8,8). It's broadcasting\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # 以注意權重對 v 做加權平均（weighted average）\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "BCwhyenso7uy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = None\n",
        "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"output:\", output)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights:\", attention_weights)\n",
        "\n",
        "#the shape of out still remain (2,8,4). 2 sentences, 8 token long for each sentence and embedding dimension 4. But right now, it has the context and was distilled to a abstract concept of language."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE3PR6MCo-7Q",
        "outputId": "d5636d8e-67b1-4c0a-9942-380389e5e2e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tf.Tensor(\n",
            "[[[0.37503877 0.37483668 0.37476867 0.5000282 ]\n",
            "  [0.37502438 0.37511772 0.37519014 0.49994114]\n",
            "  [0.37503293 0.37483528 0.37478346 0.5000274 ]\n",
            "  [0.37501353 0.37503815 0.3750946  0.4999665 ]\n",
            "  [0.37510934 0.37494516 0.37524468 0.49986196]\n",
            "  [0.37493    0.3749708  0.3748445  0.50008416]\n",
            "  [0.3750102  0.37502003 0.3750882  0.49997044]\n",
            "  [0.3750102  0.37502003 0.3750882  0.49997044]]\n",
            "\n",
            " [[0.6249836  0.24989888 0.6251846  0.37512416]\n",
            "  [0.6251292  0.24986142 0.62527835 0.3749935 ]\n",
            "  [0.62520736 0.24996257 0.62496185 0.37484828]\n",
            "  [0.6249967  0.25001025 0.6247388  0.3748665 ]\n",
            "  [0.6247175  0.25020915 0.62488866 0.37517145]\n",
            "  [0.6248705  0.25025666 0.62495786 0.37509418]\n",
            "  [0.62469816 0.25012064 0.62472105 0.3750088 ]\n",
            "  [0.62486124 0.2501091  0.6251812  0.37513983]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "attention_weights: tf.Tensor(\n",
            "[[[0.12520313 0.12484732 0.1251915  0.12492963 0.12490601 0.12505633\n",
            "   0.12493305 0.12493305]\n",
            "  [0.12486875 0.12532677 0.1248234  0.1251326  0.12502299 0.12475641\n",
            "   0.12503454 0.12503454]\n",
            "  [0.12518916 0.12479965 0.1251921  0.12491672 0.12492707 0.12509596\n",
            "   0.12493967 0.12493967]\n",
            "  [0.12493894 0.12512045 0.12492833 0.1251021  0.12497249 0.12489771\n",
            "   0.12502    0.12502   ]\n",
            "  [0.12489339 0.12498891 0.12491678 0.12495057 0.12526539 0.12492755\n",
            "   0.12502871 0.12502871]\n",
            "  [0.12507135 0.12475    0.12511334 0.12490344 0.12495521 0.12523495\n",
            "   0.12498584 0.12498584]\n",
            "  [0.12494142 0.12502144 0.12495036 0.12501906 0.12504971 0.12497919\n",
            "   0.12501942 0.12501942]\n",
            "  [0.12494142 0.12502144 0.12495036 0.12501906 0.12504971 0.12497919\n",
            "   0.12501942 0.12501942]]\n",
            "\n",
            " [[0.12522529 0.1251336  0.12487742 0.1248582  0.12500982 0.12488906\n",
            "   0.12492812 0.12507845]\n",
            "  [0.12513208 0.12522227 0.12498537 0.12483539 0.12490731 0.12495412\n",
            "   0.124829   0.12513447]\n",
            "  [0.12488572 0.12499519 0.12517586 0.12510268 0.12491465 0.12504792\n",
            "   0.12494768 0.12493031]\n",
            "  [0.12485623 0.12483494 0.1250924  0.12521482 0.1250119  0.12499835\n",
            "   0.12515691 0.12483448]\n",
            "  [0.1249623  0.12486134 0.12485887 0.12496635 0.12514055 0.12506862\n",
            "   0.12511192 0.12503006]\n",
            "  [0.12483753 0.12490408 0.12498801 0.12494874 0.12506457 0.1251921\n",
            "   0.12498959 0.12507541]\n",
            "  [0.12488816 0.12479058 0.1248994  0.12511882 0.12511945 0.12500118\n",
            "   0.12526014 0.12492232]\n",
            "  [0.12503071 0.12508821 0.12487432 0.12478878 0.12502985 0.12507926\n",
            "   0.12491459 0.12519424]]], shape=(2, 8, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 這次讓我們將 padding mask 放入注意函式並觀察\n",
        "# 注意權重的變化\n",
        "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
        "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3pdz1YpayS",
        "outputId": "bed183e0-0e96-4c8a-9982-6c9d490dc9fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[0.16690771 0.1664334  0.1668922  0.16654311 0.16651163 0.166712\n",
            "   0.         0.        ]\n",
            "  [0.166507   0.16711776 0.16644654 0.16685885 0.16671269 0.1663572\n",
            "   0.         0.        ]\n",
            "  [0.166892   0.16637276 0.16689594 0.16652882 0.16654263 0.16676779\n",
            "   0.         0.        ]\n",
            "  [0.16659412 0.16683616 0.16657998 0.16681169 0.16663887 0.16653915\n",
            "   0.         0.        ]\n",
            "  [0.16653727 0.16666463 0.16656846 0.1666135  0.16703331 0.16658282\n",
            "   0.         0.        ]\n",
            "  [0.16675551 0.16632706 0.1668115  0.16653164 0.16660066 0.16697362\n",
            "   0.         0.        ]\n",
            "  [0.16659719 0.1667039  0.16660911 0.1667007  0.1667416  0.16664755\n",
            "   0.         0.        ]\n",
            "  [0.16659719 0.1667039  0.16660911 0.1667007  0.1667416  0.16664755\n",
            "   0.         0.        ]]\n",
            "\n",
            " [[0.12522529 0.1251336  0.12487742 0.1248582  0.12500982 0.12488906\n",
            "   0.12492812 0.12507845]\n",
            "  [0.12513208 0.12522227 0.12498537 0.12483539 0.12490731 0.12495412\n",
            "   0.124829   0.12513447]\n",
            "  [0.12488572 0.12499519 0.12517586 0.12510268 0.12491465 0.12504792\n",
            "   0.12494768 0.12493031]\n",
            "  [0.12485623 0.12483494 0.1250924  0.12521482 0.1250119  0.12499835\n",
            "   0.12515691 0.12483448]\n",
            "  [0.1249623  0.12486134 0.12485887 0.12496635 0.12514055 0.12506862\n",
            "   0.12511192 0.12503006]\n",
            "  [0.12483753 0.12490408 0.12498801 0.12494874 0.12506457 0.1251921\n",
            "   0.12498959 0.12507541]\n",
            "  [0.12488816 0.12479058 0.1248994  0.12511882 0.12511945 0.12500118\n",
            "   0.12526014 0.12492232]\n",
            "  [0.12503071 0.12508821 0.12487432 0.12478878 0.12502985 0.12507926\n",
            "   0.12491459 0.12519424]]], shape=(2, 8, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立一個 2 維矩陣，維度為 (size, size)，\n",
        "# 其遮罩為一個右上角的三角形\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
        "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask\", look_ahead_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igmroCsKpfbs",
        "outputId": "ecc68774-c083-43d1-b8ff-085c66dfd858"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.02015215 -0.03247251  0.0031804   0.04034558]\n",
            "  [ 0.01854307 -0.00956931 -0.04446508  0.03501644]\n",
            "  [ 0.02089332  0.01845915  0.0454005   0.04727472]\n",
            "  [ 0.02104043  0.00698375  0.03782404 -0.00816789]\n",
            "  [-0.02533319 -0.03234955  0.0007451   0.02777502]\n",
            "  [-0.01254399 -0.03387081  0.03413624  0.01327163]\n",
            "  [ 0.02627933  0.03917975  0.02991945  0.04960121]\n",
            "  [ 0.03275328  0.00323802  0.04418768  0.018262  ]\n",
            "  [ 0.03275328  0.00323802  0.04418768  0.018262  ]\n",
            "  [ 0.03275328  0.00323802  0.04418768  0.018262  ]]\n",
            "\n",
            " [[-0.02015215 -0.03247251  0.0031804   0.04034558]\n",
            "  [ 0.01204992 -0.01843065  0.03811884 -0.00427923]\n",
            "  [-0.02281092 -0.01267733  0.0431917   0.01321609]\n",
            "  [ 0.00104873  0.03944485  0.04170216  0.03172455]\n",
            "  [-0.0088837  -0.01758944  0.01433395  0.047419  ]\n",
            "  [ 0.04414204  0.00638245  0.03439586  0.01254776]\n",
            "  [ 0.04537058 -0.00951792  0.0389039   0.02454723]\n",
            "  [ 0.02761051 -0.0353259  -0.03422016 -0.02444232]\n",
            "  [-0.01254399 -0.03387081  0.03413624  0.01327163]\n",
            "  [ 0.02627933  0.03917975  0.02991945  0.04960121]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 讓我們用目標語言（中文）的 batch\n",
        "# 來模擬 Decoder 處理的情況\n",
        "temp_q = temp_k = emb_tar\n",
        "temp_v = tf.cast(tf.math.greater(\n",
        "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
        "\n",
        "# 將 look_ahead_mask 放入注意函式\n",
        "_, attention_weights = scaled_dot_product_attention(\n",
        "    temp_q, temp_k, temp_v, look_ahead_mask)\n",
        "\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVwnbxJ_pl2R",
        "outputId": "dd55f543-46f2-4830-d17a-82d4f9aa3279"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.49969622 0.5003038  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.33317438 0.33297724 0.33384842 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.24984922 0.24975123 0.2501942  0.25020537 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.2001647  0.19997416 0.19991831 0.19980058 0.20014232 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.16672942 0.16648299 0.1666705  0.16661987 0.16671364 0.16678354\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.14275147 0.14276749 0.14308597 0.14284134 0.1426924  0.14273208\n",
            "   0.1431293  0.         0.         0.        ]\n",
            "  [0.12490831 0.12485456 0.1251272  0.12504092 0.12487669 0.12497817\n",
            "   0.12510228 0.12511192 0.         0.        ]\n",
            "  [0.11101857 0.11097079 0.1112131  0.11113642 0.11099046 0.11108065\n",
            "   0.11119097 0.11119953 0.11119953 0.        ]\n",
            "  [0.09990876 0.09986576 0.10008383 0.10001482 0.09988347 0.09996463\n",
            "   0.10006391 0.10007162 0.10007162 0.10007162]]\n",
            "\n",
            " [[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.4997935  0.5002065  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.33326745 0.33326855 0.333464   0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.2497998  0.24987836 0.24999794 0.25032392 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.20008725 0.19987243 0.19998349 0.19995624 0.20010059 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.1665183  0.16669767 0.16660531 0.16673589 0.16660698 0.1668359\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.14273931 0.14285293 0.14278083 0.14285101 0.14280906 0.14295925\n",
            "   0.14300765 0.         0.         0.        ]\n",
            "  [0.12500434 0.12502235 0.12491195 0.12481306 0.12495628 0.12500522\n",
            "   0.12501447 0.12527232 0.         0.        ]\n",
            "  [0.1111456  0.11113008 0.11116607 0.11106219 0.1111361  0.11106638\n",
            "   0.11111283 0.11099903 0.11118168 0.        ]\n",
            "  [0.09993022 0.09994162 0.09995805 0.10013527 0.10000838 0.10006857\n",
            "   0.10007554 0.09977099 0.09991665 0.10019471]]], shape=(2, 10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multi-head split the demension of embedding, process them seperately\n",
        "\n",
        "def split_heads(x, d_model, num_heads):\n",
        "  # x.shape: (batch_size, seq_len, d_model)\n",
        "  batch_size = tf.shape(x)[0]\n",
        "\n",
        "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
        "  assert d_model % num_heads == 0\n",
        "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度\n",
        "\n",
        "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
        "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
        "  # fill in the rest to -1 dimenstion\n",
        "  # (batch_size, seq_len, num_heads, depth)\n",
        "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
        "\n",
        "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
        "  # change the sequence of dimension for better understanding.\n",
        "  # (batch_size, num_heads, seq_len, depth)\n",
        "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  return output\n",
        "\n",
        "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
        "d_model = 4\n",
        "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
        "num_heads = 2\n",
        "x = emb_inp\n",
        "\n",
        "output = split_heads(x, d_model, num_heads)\n",
        "print(\"x:\", x)\n",
        "print(\"output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAq54KzbpmrA",
        "outputId": "5ed9e7e2-f2a9-4c69-e338-8c39d8ebb5d9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tf.Tensor(\n",
            "[[[ 0.02491589 -0.02200254 -0.04660983  0.01266989]\n",
            "  [ 0.0310004   0.04806106  0.04239729  0.0005783 ]\n",
            "  [ 0.01260966 -0.03079386 -0.04479383  0.0136128 ]\n",
            "  [ 0.02154765 -0.00330728  0.03435011  0.00439563]\n",
            "  [-0.04063923  0.02156777  0.00966756  0.04923698]\n",
            "  [-0.03219175 -0.03908183 -0.02750939 -0.01962395]\n",
            "  [-0.00919344  0.00048485  0.01551192  0.0064572 ]\n",
            "  [-0.00919344  0.00048485  0.01551192  0.0064572 ]]\n",
            "\n",
            " [[ 0.02491589 -0.02200254 -0.04660983  0.01266989]\n",
            "  [ 0.00956548 -0.01062233 -0.04241183 -0.03755885]\n",
            "  [ 0.00961833  0.02037785  0.03285099 -0.03046663]\n",
            "  [-0.00464127  0.03901367  0.03678637  0.02012551]\n",
            "  [-0.02847431 -0.02700673  0.00728267  0.03537157]\n",
            "  [-0.03839296 -0.03189359  0.03233362 -0.01401182]\n",
            "  [-0.04063923  0.02156777  0.00966756  0.04923698]\n",
            "  [-0.03219175 -0.03908183 -0.02750939 -0.01962395]]], shape=(2, 8, 4), dtype=float32)\n",
            "output: tf.Tensor(\n",
            "[[[[ 0.02491589 -0.02200254]\n",
            "   [ 0.0310004   0.04806106]\n",
            "   [ 0.01260966 -0.03079386]\n",
            "   [ 0.02154765 -0.00330728]\n",
            "   [-0.04063923  0.02156777]\n",
            "   [-0.03219175 -0.03908183]\n",
            "   [-0.00919344  0.00048485]\n",
            "   [-0.00919344  0.00048485]]\n",
            "\n",
            "  [[-0.04660983  0.01266989]\n",
            "   [ 0.04239729  0.0005783 ]\n",
            "   [-0.04479383  0.0136128 ]\n",
            "   [ 0.03435011  0.00439563]\n",
            "   [ 0.00966756  0.04923698]\n",
            "   [-0.02750939 -0.01962395]\n",
            "   [ 0.01551192  0.0064572 ]\n",
            "   [ 0.01551192  0.0064572 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.02491589 -0.02200254]\n",
            "   [ 0.00956548 -0.01062233]\n",
            "   [ 0.00961833  0.02037785]\n",
            "   [-0.00464127  0.03901367]\n",
            "   [-0.02847431 -0.02700673]\n",
            "   [-0.03839296 -0.03189359]\n",
            "   [-0.04063923  0.02156777]\n",
            "   [-0.03219175 -0.03908183]]\n",
            "\n",
            "  [[-0.04660983  0.01266989]\n",
            "   [-0.04241183 -0.03755885]\n",
            "   [ 0.03285099 -0.03046663]\n",
            "   [ 0.03678637  0.02012551]\n",
            "   [ 0.00728267  0.03537157]\n",
            "   [ 0.03233362 -0.01401182]\n",
            "   [ 0.00966756  0.04923698]\n",
            "   [-0.02750939 -0.01962395]]]], shape=(2, 2, 8, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 實作一個執行多頭注意力機制的 keras layer\n",
        "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
        "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
        "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
        "# output.shape            == (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # 在初始的時候建立一些必要參數\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
        "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
        "\n",
        "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
        "\n",
        "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換\n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
        "\n",
        "  # 這跟我們前面看過的函式有 87% 相似\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
        "    # 輸出會多一個 head 維度\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
        "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # 通過最後一個線性轉換\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "wb57O1-mpt8J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 實作一個執行多頭注意力機制的 keras layer\n",
        "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
        "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
        "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
        "# output.shape            == (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # 在初始的時候建立一些必要參數\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
        "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
        "\n",
        "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
        "\n",
        "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換\n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
        "\n",
        "  # 這跟我們前面看過的函式有 87% 相似\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
        "    # 輸出會多一個 head 維度\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
        "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # 通過最後一個線性轉換\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "oZcKnsb0yyft"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb_inp.shape == (batch_size, seq_len, d_model)\n",
        "#               == (2, 8, 4)\n",
        "assert d_model == emb_inp.shape[-1]  == 4\n",
        "num_heads = 2\n",
        "\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"num_heads: {num_heads}\\n\")\n",
        "\n",
        "# 初始化一個 multi-head attention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# 簡單將 v, k, q 都設置為 `emb_inp`\n",
        "# 順便看看 padding mask 的作用。\n",
        "# 別忘記，第一個英文序列的最後兩個 tokens 是 <pad>\n",
        "v = k = q = emb_inp\n",
        "padding_mask = create_padding_mask(inp)\n",
        "print(\"q.shape:\", q.shape)\n",
        "print(\"k.shape:\", k.shape)\n",
        "print(\"v.shape:\", v.shape)\n",
        "print(\"padding_mask.shape:\", padding_mask.shape)\n",
        "\n",
        "output, attention_weights = mha(v, k, q, padding_mask)\n",
        "print(\"output.shape:\", output.shape)\n",
        "print(\"attention_weights.shape:\", attention_weights.shape)\n",
        "\n",
        "print(\"\\noutput:\", output)\n",
        "\n",
        "# attention_weights.shape: (2, 2, 8, 8): 2 batches, 2 heads, 8 words (attention: 8x8)\n",
        "# mask shape=(2, 1, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlaUvaTPp0Iy",
        "outputId": "eccd258c-f0ac-499c-f596-0897e7715294"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_model: 4\n",
            "num_heads: 2\n",
            "\n",
            "q.shape: (2, 8, 4)\n",
            "k.shape: (2, 8, 4)\n",
            "v.shape: (2, 8, 4)\n",
            "padding_mask.shape: (2, 1, 1, 8)\n",
            "output.shape: (2, 16, 4)\n",
            "attention_weights.shape: (2, 2, 8, 8)\n",
            "\n",
            "output: tf.Tensor(\n",
            "[[[-0.01192586 -0.00361569 -0.00251443  0.00630695]\n",
            "  [ 0.00028232 -0.00442405  0.00502314 -0.00916922]\n",
            "  [-0.01195272 -0.00364401 -0.00253466  0.00631339]\n",
            "  [ 0.00028549 -0.00440191  0.00500079 -0.00913809]\n",
            "  [-0.01193856 -0.00361816 -0.00251654  0.00630704]\n",
            "  [ 0.00028023 -0.00442868  0.00502643 -0.00917475]\n",
            "  [-0.01195775 -0.0036391  -0.00253147  0.00631183]\n",
            "  [ 0.00028086 -0.00440989  0.00500545 -0.00914688]\n",
            "  [-0.01201969 -0.00364398 -0.00253685  0.00631035]\n",
            "  [ 0.00028099 -0.00442465  0.00502254 -0.0091692 ]\n",
            "  [-0.01198298 -0.00363711 -0.00253094  0.00631014]\n",
            "  [ 0.00027021 -0.00445106  0.00504238 -0.00920149]\n",
            "  [-0.01198201 -0.00364197 -0.00253423  0.00631151]\n",
            "  [ 0.00027812 -0.0044243   0.00501934 -0.00916667]\n",
            "  [-0.01198201 -0.00364197 -0.00253423  0.00631151]\n",
            "  [ 0.00027812 -0.0044243   0.00501934 -0.00916667]]\n",
            "\n",
            " [[-0.0079847  -0.00343419  0.00057874  0.00240402]\n",
            "  [-0.00873966 -0.00474752  0.00635338 -0.01223588]\n",
            "  [-0.00798865 -0.00343062  0.00056964  0.0024169 ]\n",
            "  [-0.00876392 -0.00475182  0.00634408 -0.01223381]\n",
            "  [-0.00799058 -0.0034228   0.00055718  0.00243803]\n",
            "  [-0.00873008 -0.00473811  0.00634592 -0.01222238]\n",
            "  [-0.0079837  -0.00341967  0.00056072  0.00243842]\n",
            "  [-0.00871769 -0.00473797  0.00635365 -0.01222727]\n",
            "  [-0.00797594 -0.00341983  0.00056959  0.00242984]\n",
            "  [-0.00874076 -0.0047426   0.00634557 -0.01222628]\n",
            "  [-0.0079805  -0.00341562  0.00055896  0.00244492]\n",
            "  [-0.00875425 -0.00474096  0.00633456 -0.01221763]\n",
            "  [-0.00797436 -0.00341638  0.0005668   0.00243659]\n",
            "  [-0.00873931 -0.00474599  0.00635139 -0.01223318]\n",
            "  [-0.00798035 -0.00342253  0.00056822  0.0024279 ]\n",
            "  [-0.00877671 -0.00475203  0.00633617 -0.01222887]]], shape=(2, 16, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "ZTExr5wnOfqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PointWiseFeedForwardNetwork(d_model, dff):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(dff, activation='relu')) # (batch_size, seq_len, dff)\n",
        "  model.add(tf.keras.layers.Dense(d_model)) # (batch_size, seq_len, d_model)\n",
        "  return model"
      ],
      "metadata": {
        "id": "ANM7EzhVOkGc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "seq_len = 10\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "\n",
        "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "out = ffn(x)\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"out.shape:\", out.shape)"
      ],
      "metadata": {
        "id": "h5j9VHYVYG2H",
        "outputId": "82c76d65-fa81-4a12-dd93-57ba97eceabc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: (64, 10, 512)\n",
            "out.shape: (64, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One encoder = MHA + FNN\n",
        "#Layer normalization + residual\n",
        "# sub_layer_out = Sublayer(x)\n",
        "# sub_layer_out = Dropout(sub_layer_out)\n",
        "# out = LayerNorm(x + sub_layer_out)\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "    #layer normalization\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    #dropout\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def __call__(self, x, training, mask):\n",
        "\n",
        "    # sub-layer 1: MHA\n",
        "    attn_output, attn = self.mha(x, x, x, mask)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "    # sub-layer 2: FNN\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    output2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "    return output2\n",
        "\n"
      ],
      "metadata": {
        "id": "hdAlg4mrYRZt"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
        "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
        "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"padding_mask:\", padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_inp:\", emb_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "assert emb_inp.shape == enc_out.shape"
      ],
      "metadata": {
        "id": "Z_aNbMCGbcRg",
        "outputId": "4d8f43eb-08f4-4d6f-e102-63f0621bbc8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here\n",
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "emb_inp: tf.Tensor(\n",
            "[[[-0.00199723  0.00680826  0.01488414  0.0447016 ]\n",
            "  [-0.00579196  0.03432131 -0.01127356 -0.01371051]\n",
            "  [-0.01317365 -0.01123785 -0.02717954 -0.00209483]\n",
            "  [-0.02212193  0.03168967  0.00634627  0.02523938]\n",
            "  [ 0.01858512  0.01957585 -0.01394806 -0.0028327 ]\n",
            "  [-0.04932721  0.02893816 -0.01498246 -0.04549257]\n",
            "  [-0.0367211  -0.03001974 -0.00548104  0.01677741]\n",
            "  [-0.0367211  -0.03001974 -0.00548104  0.01677741]]\n",
            "\n",
            " [[-0.00199723  0.00680826  0.01488414  0.0447016 ]\n",
            "  [-0.01424537  0.04252477 -0.04461938  0.03427823]\n",
            "  [ 0.00012944 -0.03766169  0.01255461  0.01765216]\n",
            "  [-0.02862835  0.04016503  0.02635698  0.04124168]\n",
            "  [-0.03105009  0.04924557 -0.0452176   0.02693221]\n",
            "  [ 0.01053728  0.00994729 -0.00897037  0.02762072]\n",
            "  [ 0.01858512  0.01957585 -0.01394806 -0.0028327 ]\n",
            "  [-0.04932721  0.02893816 -0.01498246 -0.04549257]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-1.6454984   0.04224796  0.74995214  0.85329837]\n",
            "  [-0.5321725   1.5868036   0.0395712  -1.0942023 ]\n",
            "  [-1.6096575   1.1181029   0.10788421  0.3836704 ]\n",
            "  [-1.4994646   1.2146448   0.48568624 -0.20086645]\n",
            "  [-0.35508418  1.7093828  -0.54512864 -0.80916977]\n",
            "  [-0.5868041   1.3830537   0.44621366 -1.2424632 ]\n",
            "  [-1.5666838  -0.17268935  0.9082097   0.8311635 ]\n",
            "  [-1.5666838  -0.17268935  0.9082097   0.8311635 ]]\n",
            "\n",
            " [[-1.7153519   0.6239074   0.736348    0.35509664]\n",
            "  [-1.0667053   1.6348692  -0.4022567  -0.16590723]\n",
            "  [-1.4354944  -0.3912447   1.1560549   0.67068434]\n",
            "  [-1.4352026   1.1884977   0.62196565 -0.37526062]\n",
            "  [-1.035069    1.6529893  -0.25728425 -0.36063588]\n",
            "  [-1.4003191   1.4277941  -0.00577289 -0.0217022 ]\n",
            "  [-0.38595825  1.6397411  -0.19313036 -1.0606523 ]\n",
            "  [-0.5601395   1.3725895   0.45173836 -1.2641884 ]]], shape=(2, 8, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = PointWiseFeedForwardNetwork(d_model, dff)\n",
        "\n",
        "    #LayerNorm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    #Dropout\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def __call__(self, x, enc_output, training, combined_mask, inp_padding_mask):\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, inp_padding_mask)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "    ffn_output = self.ffn(out2)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zlsCOMSdesbB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_padding_mask:\", tar_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask:\", look_ahead_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)"
      ],
      "metadata": {
        "id": "GmV8g4AGgOPL",
        "outputId": "75b7a17f-c51b-4ccf-abce-8bd8d6aa9d39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask: tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
        "\n",
        "# 來源、目標語言的序列都需要 padding mask\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "\n",
        "# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算\n",
        "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
        "    emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_out:\", dec_out)\n",
        "assert emb_tar.shape == dec_out.shape\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
        "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)"
      ],
      "metadata": {
        "id": "LzSV1u4AgQWZ",
        "outputId": "5fd81398-be17-4731-eb1e-e001b5e7a364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.03373228 -0.03886728 -0.04052199 -0.00955547]\n",
            "  [ 0.00309727  0.01263506 -0.01082643  0.03708297]\n",
            "  [ 0.00894903 -0.04663102 -0.00850056 -0.03314763]\n",
            "  [-0.02755705  0.00652428  0.00884439  0.00857745]\n",
            "  [-0.00100239 -0.00545176 -0.0256992   0.00959864]\n",
            "  [ 0.03556677 -0.0241802  -0.00550144  0.01574165]\n",
            "  [-0.01121855  0.01493908 -0.03981457  0.04909338]\n",
            "  [-0.02114817  0.04496567 -0.00567023  0.03220527]\n",
            "  [-0.02114817  0.04496567 -0.00567023  0.03220527]\n",
            "  [-0.02114817  0.04496567 -0.00567023  0.03220527]]\n",
            "\n",
            " [[-0.03373228 -0.03886728 -0.04052199 -0.00955547]\n",
            "  [-0.01923163  0.01217077  0.02731622 -0.02458288]\n",
            "  [ 0.00741919  0.01664327 -0.01079142 -0.00200734]\n",
            "  [-0.01870476 -0.02902025 -0.00527334  0.0432407 ]\n",
            "  [-0.0083392   0.03258276  0.04262007  0.01954139]\n",
            "  [ 0.00024738  0.01509402 -0.00632627 -0.00339556]\n",
            "  [-0.0274243   0.01855371  0.00460332 -0.04774611]\n",
            "  [-0.0433907   0.02001016  0.02617599 -0.00279851]\n",
            "  [ 0.03556677 -0.0241802  -0.00550144  0.01574165]\n",
            "  [-0.01121855  0.01493908 -0.03981457  0.04909338]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-1.2479876  -0.6030467   0.49791273  1.3531216 ]\n",
            "  [-1.2697417   0.07364571 -0.31491598  1.511012  ]\n",
            "  [-0.1435784   0.9549525  -1.575791    0.7644168 ]\n",
            "  [-0.3119604   1.0427773  -1.4941796   0.76336265]\n",
            "  [-0.7603905   0.85467887 -1.2062135   1.111925  ]\n",
            "  [-1.2779139   0.00324053 -0.2442882   1.5189615 ]\n",
            "  [-1.2953848  -0.3833673   0.22054757  1.4582045 ]\n",
            "  [-1.3159415  -0.18945211  0.01131358  1.4940801 ]]\n",
            "\n",
            " [[-1.2552037  -0.58225244  0.4730162   1.36444   ]\n",
            "  [-0.8783725   0.56114006 -1.0378914   1.3551238 ]\n",
            "  [-0.17632902  0.9366704  -1.5639138   0.8035724 ]\n",
            "  [-0.30974615  1.0328711  -1.4964147   0.7732897 ]\n",
            "  [-0.8955377   0.74588835 -1.0720108   1.2216599 ]\n",
            "  [-1.2367237   0.15866089 -0.42642888  1.5044917 ]\n",
            "  [-1.2928969  -0.42658246  0.28175396  1.4377254 ]\n",
            "  [-1.2443992  -0.6363886   0.5677044   1.3130836 ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[ 0.5562454   0.32006043 -1.7038928   0.8275871 ]\n",
            "  [ 0.53826374  0.17435533 -1.6651176   0.95249856]\n",
            "  [ 1.3734096  -0.42093816 -1.3373263   0.3848548 ]\n",
            "  [-0.77278554  0.7995889  -1.1887949   1.1619915 ]\n",
            "  [ 0.5277716   0.4772482  -1.7249372   0.7199175 ]\n",
            "  [ 1.0258633  -0.29146415 -1.5058348   0.77143556]\n",
            "  [ 0.07030502  0.61513245 -1.6430562   0.95761883]\n",
            "  [-0.3628357   1.1610037  -1.4483415   0.65017354]\n",
            "  [-0.3628357   1.1610037  -1.4483415   0.65017354]\n",
            "  [-0.3628357   1.1610037  -1.4483415   0.65017354]]\n",
            "\n",
            " [[ 0.60955083  0.21653777 -1.6859045   0.85981596]\n",
            "  [-1.4783084   1.3415977   0.01653875  0.12017202]\n",
            "  [ 0.34401956  0.98044205 -1.6729938   0.34853205]\n",
            "  [ 0.2967945  -0.7819579  -1.0189174   1.5040809 ]\n",
            "  [-1.1298766   0.08827847 -0.52158207  1.5631802 ]\n",
            "  [ 0.69617224  1.0772473  -1.5121586  -0.26126093]\n",
            "  [-1.1448046   1.5465645   0.12840092 -0.53016067]\n",
            "  [-1.2464573   0.4602936  -0.58810186  1.3742654 ]\n",
            "  [ 1.0821477  -1.1270888  -0.86003006  0.9049711 ]\n",
            "  [-0.03088407  0.36018398 -1.5457894   1.2164896 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_self_attn_weights.shape: (2, 2, 10, 10)\n",
            "dec_enc_attn_weights: (2, 2, 10, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 以下直接參考 TensorFlow 官方 tutorial\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "\n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "d_model = 512\n",
        "\n",
        "pos_encoding = positional_encoding(seq_len, d_model)\n",
        "pos_encoding"
      ],
      "metadata": {
        "id": "kjV5vEHag6qn",
        "outputId": "071747a9-c6e4-4746-a670-e0c25a7dce58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
              "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        ...,\n",
              "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
              "          0.99998724,  0.99998814],\n",
              "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
              "          0.9999867 ,  0.9999876 ],\n",
              "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
              "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
        "  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
        "  # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "\n",
        "    # 建立 `num_layers` 個 EncoderLayers\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def __call__(self, x, training, mask):\n",
        "    # 輸入的 x.shape == (batch_size, input_seq_len)\n",
        "    # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
        "    input_seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
        "    # 再加上對應長度的位置編碼\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :input_seq_len, :]\n",
        "\n",
        "    # 對 embedding 跟位置編碼的總合做 regularization\n",
        "    # 這在 Decoder 也會做\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    # 通過 N 個 EncoderLayer 做編碼\n",
        "    for i, enc_layer in enumerate(self.enc_layers):\n",
        "      x = enc_layer(x, training, mask)\n",
        "      # 以下只是用來 demo EncoderLayer outputs\n",
        "      #print('-' * 20)\n",
        "      #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
        "\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "5XGpm3b5hDH6"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Encoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 初始化一個 Encoder\n",
        "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
        "enc_out = encoder(inp, training=False, mask=None)\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)"
      ],
      "metadata": {
        "id": "njST86Z8jIaL",
        "outputId": "1053321f-7939-4615-c73c-75dafd17aea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-1.0977111  -0.7096808   0.33009046  1.4773015 ]\n",
            "  [-1.063536   -0.76076555  0.3526486   1.471653  ]\n",
            "  [-1.0874604  -0.8401524   0.60763186  1.319981  ]\n",
            "  [-1.4421477  -0.3968769   0.73018754  1.1088371 ]\n",
            "  [-1.5926481  -0.10943197  0.81258744  0.8894927 ]\n",
            "  [-1.4226431  -0.37194747  0.5600541   1.2345362 ]\n",
            "  [-1.2297897  -0.5641749   0.36775357  1.4262111 ]\n",
            "  [-1.2220149  -0.57371485  0.36626136  1.4294685 ]]\n",
            "\n",
            " [[-1.1054729  -0.7086621   0.3457383   1.4683968 ]\n",
            "  [-1.1484367  -0.6654576   0.3623602   1.451534  ]\n",
            "  [-0.7286333  -0.97053266  0.113525    1.5856408 ]\n",
            "  [-1.3609293  -0.5365287   0.7757671   1.1216909 ]\n",
            "  [-1.5400994  -0.23243856  0.84677565  0.92576224]\n",
            "  [-1.5095598  -0.239614    0.6157357   1.1334381 ]\n",
            "  [-1.2988261  -0.49521726  0.4182151   1.3758283 ]\n",
            "  [-1.0603216  -0.7711909   0.36631986  1.4651926 ]]], shape=(2, 8, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "\n",
        "    # 為中文（目標語言）建立詞嵌入層\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
        "  def call(self, x, enc_output, training,\n",
        "           combined_mask, inp_padding_mask):\n",
        "\n",
        "    tar_seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
        "\n",
        "    # 這邊跟 Encoder 做的事情完全一樣\n",
        "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "\n",
        "    for i, dec_layer in enumerate(self.dec_layers):\n",
        "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
        "                                    combined_mask, inp_padding_mask)\n",
        "\n",
        "      # 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察\n",
        "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "\n",
        "    # x.shape == (batch_size, tar_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "metadata": {
        "id": "QQI2IiUXlaiY"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Decoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 遮罩\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化一個 Decoder\n",
        "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_padding_mask:\", inp_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "dec_out, attn = decoder(tar, enc_out, training=False,\n",
        "                        combined_mask=combined_mask,\n",
        "                        inp_padding_mask=inp_padding_mask)\n",
        "print(\"dec_out:\", dec_out)\n",
        "print(\"-\" * 20)\n",
        "for block_name, attn_weights in attn.items():\n",
        "  print(f\"{block_name}.shape: {attn_weights.shape}\")"
      ],
      "metadata": {
        "id": "fnNmeo21n0SX",
        "outputId": "04d1a74e-345f-498d-e398-7eda3941dc06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-1.0977111  -0.7096808   0.33009046  1.4773015 ]\n",
            "  [-1.063536   -0.76076555  0.3526486   1.471653  ]\n",
            "  [-1.0874604  -0.8401524   0.60763186  1.319981  ]\n",
            "  [-1.4421477  -0.3968769   0.73018754  1.1088371 ]\n",
            "  [-1.5926481  -0.10943197  0.81258744  0.8894927 ]\n",
            "  [-1.4226431  -0.37194747  0.5600541   1.2345362 ]\n",
            "  [-1.2297897  -0.5641749   0.36775357  1.4262111 ]\n",
            "  [-1.2220149  -0.57371485  0.36626136  1.4294685 ]]\n",
            "\n",
            " [[-1.1054729  -0.7086621   0.3457383   1.4683968 ]\n",
            "  [-1.1484367  -0.6654576   0.3623602   1.451534  ]\n",
            "  [-0.7286333  -0.97053266  0.113525    1.5856408 ]\n",
            "  [-1.3609293  -0.5365287   0.7757671   1.1216909 ]\n",
            "  [-1.5400994  -0.23243856  0.84677565  0.92576224]\n",
            "  [-1.5095598  -0.239614    0.6157357   1.1334381 ]\n",
            "  [-1.2988261  -0.49521726  0.4182151   1.3758283 ]\n",
            "  [-1.0603216  -0.7711909   0.36631986  1.4651926 ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "inp_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[-1.2219155   0.18290585 -0.46377906  1.5027885 ]\n",
            "  [-0.35219482 -0.30272692 -1.008549    1.6634707 ]\n",
            "  [-0.71817803  0.11992264 -0.9836185   1.5818739 ]\n",
            "  [-1.3796369   1.1765089  -0.48656574  0.6896938 ]\n",
            "  [-1.4840455   1.1507263  -0.29044163  0.6237608 ]\n",
            "  [-1.4836773   1.2639557  -0.18760793  0.40732953]\n",
            "  [-1.4631964   1.3360181  -0.11810017  0.24527833]\n",
            "  [-1.3039433   1.5055945  -0.02150613 -0.18014508]\n",
            "  [-0.4476226   0.9190352  -1.4281573   0.9567447 ]\n",
            "  [-1.1464278   1.3913848  -0.7223712   0.47741395]]\n",
            "\n",
            " [[-1.1464223   0.10940102 -0.5149392   1.5519605 ]\n",
            "  [-0.52882457 -0.2612489  -0.89724374  1.6873173 ]\n",
            "  [-0.3944116   0.27496493 -1.3117156   1.4311622 ]\n",
            "  [-1.3906938   1.1937795  -0.4589784   0.6558926 ]\n",
            "  [-1.4496799   1.2444811  -0.30276296  0.5079619 ]\n",
            "  [-1.4884769   1.2451744  -0.19801675  0.4413193 ]\n",
            "  [-1.4709635   1.3266749  -0.10922182  0.25351048]\n",
            "  [-1.4137726   1.4122603  -0.05740047  0.05891271]\n",
            "  [ 0.57246023  0.23073715 -1.6854349   0.88223773]\n",
            "  [-1.1383832   1.4740796  -0.6550958   0.3193994 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "decoder_layer1_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer1_block2.shape: (2, 2, 10, 8)\n",
            "decoder_layer2_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer2_block2.shape: (2, 2, 10, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型\n",
        "class Transformer(tf.keras.Model):\n",
        "  # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, rate)\n",
        "    # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
        "  # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
        "  def __call__(self, inp, tar, training, enc_padding_mask,\n",
        "           combined_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
        "\n",
        "    # 將 Decoder 輸出通過最後一個 linear layer\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "metadata": {
        "id": "OsSlGoPun3ag"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數\n",
        "num_layers = 1\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# + 2 是為了 <start> & <end> token\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
        "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 重點中的重點。訓練時用前一個字來預測下一個中文字\n",
        "tar_inp = tar[:, :-1]\n",
        "tar_real = tar[:, 1:]\n",
        "\n",
        "# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar_inp)\n",
        "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化我們的第一個 transformer\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, output_vocab_size)\n",
        "\n",
        "# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果\n",
        "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask,\n",
        "                                        combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_inp:\", tar_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_real:\", tar_real)\n",
        "print(\"-\" * 20)\n",
        "print(\"predictions:\", predictions)"
      ],
      "metadata": {
        "id": "l1-vJi5ToQWy",
        "outputId": "7736db1a-495f-4c59-a286-50a6d4dfa4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_inp: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "tar_real: tf.Tensor(\n",
            "[[  10  241   86   27    3 4206    0    0    0]\n",
            " [ 165  489  398  191   14    7  560    3 4206]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "predictions: tf.Tensor(\n",
            "[[[-0.01940956 -0.07217779  0.02303033 ...  0.01355333  0.08088134\n",
            "    0.03208076]\n",
            "  [-0.01232646 -0.05219657  0.02463093 ... -0.00843086  0.10425846\n",
            "    0.05753477]\n",
            "  [-0.00592067 -0.04067339  0.0246183  ... -0.01768937  0.10763258\n",
            "    0.06375175]\n",
            "  ...\n",
            "  [-0.01609942 -0.06758446  0.02475345 ...  0.00610866  0.09141683\n",
            "    0.04131894]\n",
            "  [-0.01320733 -0.05159393  0.02423278 ... -0.00858085  0.10427886\n",
            "    0.05813729]\n",
            "  [-0.00546695 -0.03621745  0.02382074 ... -0.02039918  0.10787176\n",
            "    0.06600305]]\n",
            "\n",
            " [[-0.01893672 -0.07334472  0.02317913 ...  0.0147074   0.07933798\n",
            "    0.03016943]\n",
            "  [-0.01120386 -0.05341234  0.02520296 ... -0.00790708  0.10402747\n",
            "    0.05638786]\n",
            "  [-0.00601288 -0.04101623  0.02466018 ... -0.01746332  0.10760218\n",
            "    0.06358808]\n",
            "  ...\n",
            "  [-0.01562686 -0.06846936  0.02499249 ...  0.00673949  0.09080725\n",
            "    0.04025992]\n",
            "  [-0.01385206 -0.05724251  0.02478251 ... -0.0040764   0.10127353\n",
            "    0.05324606]\n",
            "  [-0.00584371 -0.04045352  0.0245965  ... -0.01783739  0.1076496\n",
            "    0.06384904]]], shape=(2, 9, 4207), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label\n",
        "real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)\n",
        "pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)\n",
        "loss_object(real, pred)"
      ],
      "metadata": {
        "id": "eIdl5qwsoVrH",
        "outputId": "cfe31f0b-11c9-4803-814b-8026393b0cf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.31326175, 0.31326175, 1.3132617 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JX4GzAMaoogx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. review embedding + self attention\n",
        "2. review positional encoding\n",
        "3. input of transformer\n",
        "4. How to train it?"
      ],
      "metadata": {
        "id": "VadCYB-ejCe1"
      }
    }
  ]
}