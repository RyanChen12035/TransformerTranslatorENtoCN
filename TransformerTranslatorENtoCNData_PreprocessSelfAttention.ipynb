{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Transformer* implementation by Tensorflow and make it as a EN to Zh translator\n",
        "#### What's you can learn from this notebook\n",
        "1. Word embedding and tokenization\n",
        "2. Mask mechanisim\n",
        "3. Basic structure of transformer and it's application as a translator\n",
        "4. Customized layer and model of tensorflow\n",
        "5. Checkpoint, tensorflow dashboard\n",
        "\n",
        "\n",
        "#### Reference:\n",
        "1. https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#top\n",
        "2. https://www.tensorflow.org/text/tutorials/transformer\n"
      ],
      "metadata": {
        "id": "yUuYU_Y9UiXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "1Y_asZWyUt9z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0\n",
        "clear_output()\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_J5dQqUU1Z3",
        "outputId": "6c996737-504f-4032-ab46-0df1b7f7d6c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=\"error\")\n",
        "\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "TT8-7beEU_N9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up directory\n",
        "output_dir = \"nmt\"\n",
        "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
        "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(output_dir, 'logs')\n",
        "download_dir = \"tensorflow-datasets/downloads\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)"
      ],
      "metadata": {
        "id": "E-80roiwVJrF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check out the data source we have\n",
        "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
        "pprint(tmp_builder.subsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLpRjAnLVRPU",
        "outputId": "eaf43e78-7374-4709-dac2-e6ac9c3658df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Split('train'): ['newscommentary_v14',\n",
            "                  'wikititles_v1',\n",
            "                  'uncorpus_v1',\n",
            "                  'casia2015',\n",
            "                  'casict2011',\n",
            "                  'casict2015',\n",
            "                  'datum2015',\n",
            "                  'datum2017',\n",
            "                  'neu2017'],\n",
            " Split('validation'): ['newstest2018']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download data by tfds.builder\n",
        "config = tfds.translate.wmt.WmtConfig(\n",
        "  version=tfds.core.Version('0.0.3'),\n",
        "  language_pair=(\"zh\", \"en\"),\n",
        "  subsets={\n",
        "    tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
        "  }\n",
        ")\n",
        "builder = tfds.builder(\"wmt_translate\", config=config)\n",
        "builder.download_and_prepare(download_dir=download_dir)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "hJA02j6UVpRf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set builder to dataset(data pipeline type), split it into training, validation, testing\n",
        "examples = builder.as_dataset(split=['train[:20%]','train[20%:21%]','train[21%:]'], as_supervised=True)"
      ],
      "metadata": {
        "id": "NY3PQntvW6Cu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#leave the testing examples this time.\n",
        "train_examples, val_examples, _ = examples\n",
        "print(train_examples)\n",
        "print(val_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7F-GtSBcmtG",
        "outputId": "f12196cb-10ce-42c2-c5b6-161f42e4c149"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n",
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for en, zh in train_examples.take(3):\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX4ve2FRcush",
        "outputId": "8302f71f-58c6-463c-86ec-8abca55f9a85"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word \\xe2\\x80\\x9cliberal\\xe2\\x80\\x9d \\xe2\\x80\\x93 a champion of the cause of individual freedom.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe4\\xba\\x8b\\xe5\\xae\\x9e\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe5\\xbe\\xb7\\xe5\\x9b\\xbd\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xb1\\x80\\xe5\\x8a\\xbf\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe8\\xbf\\x87\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe7\\xac\\xa6\\xe5\\x90\\x88\\xe7\\xbe\\x8e\\xe5\\x9b\\xbd\\xe6\\x89\\x80\\xe8\\xb0\\x93\\xe2\\x80\\x9c\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe2\\x80\\x9d\\xe5\\xae\\x9a\\xe4\\xb9\\x89\\xe7\\x9a\\x84\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe7\\x9a\\x84\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe5\\x85\\x9a\\xe6\\xb4\\xbe\\xef\\xbc\\x8c\\xe4\\xb9\\x9f\\xe5\\xb0\\xb1\\xe6\\x98\\xaf\\xe4\\xb8\\xaa\\xe4\\xba\\xba\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe4\\xba\\x8b\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x80\\xa1\\xe5\\xaf\\xbc\\xe8\\x80\\x85\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe5\\xbf\\x85\\xe9\\xa1\\xbb\\xe4\\xbb\\x98\\xe5\\x87\\xba\\xe5\\xb7\\xa8\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\x92\\x8c\\xe5\\x9f\\xba\\xe7\\xa1\\x80\\xe8\\xae\\xbe\\xe6\\x96\\xbd\\xe6\\x8a\\x95\\xe8\\xb5\\x84\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\xae\\x8c\\xe6\\x88\\x90\\xe5\\x90\\x91\\xe5\\x8f\\xaf\\xe5\\x86\\x8d\\xe7\\x94\\x9f\\xe8\\x83\\xbd\\xe6\\xba\\x90\\xe7\\x9a\\x84\\xe8\\xbf\\x87\\xe6\\xb8\\xa1\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_examples = []\n",
        "num_samples = 10\n",
        "\n",
        "for en_t, zh_t in train_examples.take(num_samples):\n",
        "  en = en_t.numpy().decode(\"utf-8\")\n",
        "  zh = zh_t.numpy().decode(\"utf-8\")\n",
        "\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "\n",
        "\n",
        "  sample_examples.append((en, zh))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwRnP2H6cxDB",
        "outputId": "93cd0601-fbeb-41ee-ba67-e4856ecc8bc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fear is real and visceral, and politicians ignore it at their peril.\n",
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "----------\n",
            "In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word “liberal” – a champion of the cause of individual freedom.\n",
            "事实上，德国政治局势需要的不过是一个符合美国所谓“自由”定义的真正的自由党派，也就是个人自由事业的倡导者。\n",
            "----------\n",
            "Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.\n",
            "必须付出巨大的努力和基础设施投资才能完成向可再生能源的过渡。\n",
            "----------\n",
            "In this sense, it is critical to recognize the fundamental difference between “urban villages” and their rural counterparts.\n",
            "在这方面，关键在于认识到“城市村落”和农村村落之间的根本区别。\n",
            "----------\n",
            "A strong European voice, such as Nicolas Sarkozy’s during the French presidency of the EU, may make a difference, but only for six months, and at the cost of reinforcing other European countries’ nationalist feelings in reaction to the expression of “Gallic pride.”\n",
            "法国担任轮值主席国期间尼古拉·萨科奇统一的欧洲声音可能让人耳目一新，但这种声音却只持续了短短六个月，而且付出了让其他欧洲国家在面对“高卢人的骄傲”时民族主义情感进一步被激发的代价。\n",
            "----------\n",
            "Most of Japan’s bondholders are nationals (if not the central bank) and have an interest in political stability.\n",
            "日本债券持有人大多为本国国民（甚至中央银行 ） ， 政治稳定符合他们的利益。\n",
            "----------\n",
            "Paul Romer, one of the originators of new growth theory, has accused some leading names, including the Nobel laureate Robert Lucas, of what he calls “mathiness” – using math to obfuscate rather than clarify.\n",
            "新增长理论创始人之一的保罗·罗默（Paul Romer）也批评一些著名经济学家，包括诺贝尔奖获得者罗伯特·卢卡斯（Robert Lucas）在内，说他们“数学性 ” （ 罗默的用语）太重，结果是让问题变得更加模糊而不是更加清晰。\n",
            "----------\n",
            "It is, in fact, a capsule depiction of the United States Federal Reserve and the European Central Bank.\n",
            "事实上，这就是对美联储和欧洲央行的简略描述。\n",
            "----------\n",
            "Given these variables, the degree to which migration is affected by asylum-seekers will not be easy to predict or control.\n",
            "考虑到这些变量，移民受寻求庇护者的影响程度很难预测或控制。\n",
            "----------\n",
            "WASHINGTON, DC – In the 2016 American presidential election, Hillary Clinton and Donald Trump agreed that the US economy is suffering from dilapidated infrastructure, and both called for greater investment in renovating and upgrading the country’s public capital stock.\n",
            "华盛顿—在2016年美国总统选举中，希拉里·克林顿和唐纳德·特朗普都认为美国经济饱受基础设施陈旧的拖累，两人都要求加大投资用于修缮和升级美国公共资本存量。\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word tokenization\n",
        "1. Scan through the example and create a dictionary of tokens\n",
        "2. Add BOS and EOS into every sentence\n",
        "3. Set up a sentence length limitation.\n",
        "4. Padding every sentence to the same length.\n",
        "5. Index dictionary as dimension to represent tokens, reducing the dimensions by embedding\n"
      ],
      "metadata": {
        "id": "5hdIgIyIrTPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create own eng dictionary in the file of content/nmt/en_vocab #en_vocab_file\n",
        "#character-delimited + word-delimited\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
        "  print(f\"Upload the dictionary： {en_vocab_file}\")\n",
        "except:\n",
        "  print(\"No dictionary in the file path, create it.\")\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples),\n",
        "      target_vocab_size=2**13) # The size of dictionary is changable.\n",
        "  # Subwords as tokens.\n",
        "  # Save the dictionary to target file path.\n",
        "  subword_encoder_en.save_to_file(en_vocab_file)\n",
        "\n",
        "\n",
        "print(f\"size of dictionary：{subword_encoder_en.vocab_size}\")\n",
        "print(f\"first 10 subwords：{subword_encoder_en.subwords[:10]}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_h82Jm4eFD_",
        "outputId": "cc005461-f32e-427a-c9c1-783cce9d0b80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No dictionary in the file path, create it.\n",
            "size of dictionary：8113\n",
            "first 10 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
            "\n",
            "CPU times: user 1min 25s, sys: 3.64 s, total: 1min 29s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5fvarXdi4xc",
        "outputId": "55d6a85b-4c40-4122-d5dd-45badb955f44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3461, 7889, 9, 3502, 4379, 1134, 7903]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
        "print(\"-\" * 15)\n",
        "for idx in indices:\n",
        "  subword = subword_encoder_en.decode([idx])\n",
        "  print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvXXZn5sjHHs",
        "outputId": "45561362-aec4-4619-e8f2-40963e54a591"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index     Subword\n",
            "---------------\n",
            " 3461     Taiwan\n",
            " 7889      \n",
            "    9     is \n",
            " 3502     bea\n",
            " 4379     uti\n",
            " 1134     ful\n",
            " 7903     .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "try:\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
        "  print(f\"Upload the dictionary： {zh_vocab_file}\")\n",
        "except:\n",
        "  print(\"No dictionary in the file path, create it.\")\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples),\n",
        "      target_vocab_size=2**13, # A Chineses word is a token\n",
        "      max_subword_length=1)\n",
        "\n",
        "  subword_encoder_zh.save_to_file(zh_vocab_file)\n",
        "\n",
        "print(f\"size of dictionary：{subword_encoder_zh.vocab_size}\")\n",
        "print(f\"first 10 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kHMkfIWjLZh",
        "outputId": "b9788a39-8a08-4210-97dc-16c5078deba7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No dictionary in the file path, create it.\n",
            "size of dictionary：4205\n",
            "first 10 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n",
            "\n",
            "CPU times: user 6min 49s, sys: 2.73 s, total: 6min 52s\n",
            "Wall time: 6min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_string = sample_examples[0][1]\n",
        "indices = subword_encoder_zh.encode(sample_string)\n",
        "print(sample_string)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzEX-WxGjVqY",
        "outputId": "369c6b81-22a3-44f2-ec0b-132ec15ab982"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "[10, 151, 574, 1298, 6, 374, 55, 29, 193, 5, 1, 3, 3981, 931, 431, 125, 1, 17, 124, 33, 20, 97, 1089, 1247, 861, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en = \"The eurozone’s collapse forces a major realignment of European politics.\"\n",
        "zh = \"欧元区的瓦解强迫欧洲政治进行一次重大改组。\"\n",
        "\n",
        "# 將文字轉成為 subword indices\n",
        "en_indices = subword_encoder_en.encode(en)\n",
        "zh_indices = subword_encoder_zh.encode(zh)\n",
        "\n",
        "print(\"[英中原文]（轉換前）\")\n",
        "print(en)\n",
        "print(zh)\n",
        "print()\n",
        "print('-' * 20)\n",
        "print()\n",
        "print(\"[英中序列]（轉換後）\")\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUuy26KRjajN",
        "outputId": "b014c7d5-b9e0-42d0-c28c-dbab52ca29a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[英中原文]（轉換前）\n",
            "The eurozone’s collapse forces a major realignment of European politics.\n",
            "欧元区的瓦解强迫欧洲政治进行一次重大改组。\n",
            "\n",
            "--------------------\n",
            "\n",
            "[英中序列]（轉換後）\n",
            "[16, 900, 11, 6, 1527, 874, 8, 230, 2259, 2728, 239, 3, 89, 1236, 7903]\n",
            "[44, 202, 168, 1, 852, 201, 231, 592, 44, 87, 17, 124, 106, 38, 7, 279, 86, 18, 212, 265, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bos_eos(en_t, zh_t):\n",
        "  # This function will be applied to data set.\n",
        "  # Add bengin of sentence (BOS) and End of sentence (EOS) and the index of BOS and EOS are the last two index of dictionary\n",
        "  # Since the index of dictionary start with 0 so subword_encoder_en.vocab_size can be the index of BOS\n",
        "  # and subword_encoder_en.vocab_size + 1 as index of EOS\n",
        "  en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(\n",
        "      en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
        "  # Same for Zh\n",
        "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
        "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
        "\n",
        "  return en_indices, zh_indices"
      ],
      "metadata": {
        "id": "9UtvlUStk7hp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_t, zh_t = next(iter(train_examples))\n",
        "en_indices, zh_indices = add_bos_eos(en_t, zh_t)\n",
        "print('英文 BOS 的 index：', subword_encoder_en.vocab_size)\n",
        "print('英文 EOS 的 index：', subword_encoder_en.vocab_size + 1)\n",
        "print('中文 BOS 的 index：', subword_encoder_zh.vocab_size)\n",
        "print('中文 EOS 的 index：', subword_encoder_zh.vocab_size + 1)\n",
        "\n",
        "print('\\n輸入為 2 個 Tensors：')\n",
        "pprint((en_t, zh_t))\n",
        "print('-' * 15)\n",
        "print('輸出為 2 個索引序列：')\n",
        "pprint((en_indices, zh_indices))"
      ],
      "metadata": {
        "id": "4eQiwP3WlCmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96d23d0-f06a-4431-af55-26b538b91406"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文 BOS 的 index： 8113\n",
            "英文 EOS 的 index： 8114\n",
            "中文 BOS 的 index： 4205\n",
            "中文 EOS 的 index： 4206\n",
            "\n",
            "輸入為 2 個 Tensors：\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'The fear is real and visceral, and politicians ignore it at their peril.'>,\n",
            " <tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82'>)\n",
            "---------------\n",
            "輸出為 2 個索引序列：\n",
            "([8113,\n",
            "  16,\n",
            "  1284,\n",
            "  9,\n",
            "  243,\n",
            "  5,\n",
            "  1275,\n",
            "  1756,\n",
            "  156,\n",
            "  1,\n",
            "  5,\n",
            "  1016,\n",
            "  5566,\n",
            "  21,\n",
            "  38,\n",
            "  33,\n",
            "  2982,\n",
            "  7965,\n",
            "  7903,\n",
            "  8114],\n",
            " [4205,\n",
            "  10,\n",
            "  151,\n",
            "  574,\n",
            "  1298,\n",
            "  6,\n",
            "  374,\n",
            "  55,\n",
            "  29,\n",
            "  193,\n",
            "  5,\n",
            "  1,\n",
            "  3,\n",
            "  3981,\n",
            "  931,\n",
            "  431,\n",
            "  125,\n",
            "  1,\n",
            "  17,\n",
            "  124,\n",
            "  33,\n",
            "  20,\n",
            "  97,\n",
            "  1089,\n",
            "  1247,\n",
            "  861,\n",
            "  3,\n",
            "  4206])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_add_bos_eos(en_t, zh_t):\n",
        "  # Both en_t and zh_t are not eager tensors but tensors so it needs to be encapsulated using tf.py_function\n",
        "  # before applying it to tf.data.dataset.\n",
        "  # input index can use `tf.int64`\n",
        "  return tf.py_function(add_bos_eos, [en_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "# tmp_dataset` for exhibite func\n",
        "tmp_dataset = train_examples.map(tf_add_bos_eos)\n",
        "en_indices, zh_indices = next(iter(tmp_dataset))\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ishJYlKVljve",
        "outputId": "cbc79414-0d87-4da3-9cd3-573f2b2ab3e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[8113   16 1284    9  243    5 1275 1756  156    1    5 1016 5566   21\n",
            "   38   33 2982 7965 7903 8114], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[4205   10  151  574 1298    6  374   55   29  193    5    1    3 3981\n",
            "  931  431  125    1   17  124   33   20   97 1089 1247  861    3 4206], shape=(28,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
        "  # en, zh are the index list of input\n",
        "  return tf.logical_and(tf.size(en) <= max_length,\n",
        "                        tf.size(zh) <= max_length)\n",
        "\n",
        "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
        "train_dataset = tmp_dataset.filter(filter_max_length)"
      ],
      "metadata": {
        "id": "jHVJ4aUymTOs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_examples = 0\n",
        "for en_indices, zh_indices in train_dataset:\n",
        "  cond1 = len(en_indices) <= MAX_LENGTH\n",
        "  cond2 = len(zh_indices) <= MAX_LENGTH\n",
        "  assert cond1 and cond2\n",
        "  num_examples += 1\n",
        "\n",
        "print(f\"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens\")\n",
        "print(f\"訓練資料集裡總共有 {num_examples} 筆數據\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0foVyEemh8B",
        "outputId": "c99df88d-43d1-4090-abbc-c309bf15e1cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "所有英文與中文序列長度都不超過 40 個 tokens\n",
            "訓練資料集裡總共有 29784 筆數據\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "# padding the sentences.\n",
        "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "en_batch, zh_batch = next(iter(tmp_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svth2q8Km5ZY",
        "outputId": "a1cea8ec-c5dc-46f0-a6de-d816d6542c4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113   16 1284 ...    0    0    0]\n",
            " [8113   44  369 ...    0    0    0]\n",
            " [8113 1894 1302 ...    0    0    0]\n",
            " ...\n",
            " [8113 1668    1 ... 4024 7903 8114]\n",
            " [8113 5751 1538 ...    0    0    0]\n",
            " [8113 1809 5706 ...    0    0    0]], shape=(64, 71), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   10  151 ...    0    0    0]\n",
            " [4205  109   55 ...    0    0    0]\n",
            " [4205  206  275 ...    0    0    0]\n",
            " ...\n",
            " [4205   73   76 ...    0    0    0]\n",
            " [4205    5  115 ...    0    0    0]\n",
            " [4205    9  270 ...    0    0    0]], shape=(64, 116), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 40\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 15000\n",
        "\n",
        "# Training\n",
        "train_dataset = (train_examples # input: En/Zh, Output En/Zh\n",
        "                 .map(tf_add_bos_eos) # Add BOS and EOS\n",
        "                 .filter(filter_max_length) #Length <40\n",
        "                 .cache() #Speed up the process\n",
        "                 .shuffle(BUFFER_SIZE) # Shuffle the data\n",
        "                 .padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1])) # Pad to same size of example\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "# validation\n",
        "val_dataset = (val_examples\n",
        "               .map(tf_add_bos_eos)\n",
        "               .filter(filter_max_length)\n",
        "               .padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1])))"
      ],
      "metadata": {
        "id": "i2uYQzDvnDVj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_batch, zh_batch = next(iter(train_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME__uxI_nHvb",
        "outputId": "640b7744-383a-46e8-d9dd-42b893ba829c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113 3414 6021 ...    0    0    0]\n",
            " [8113 2312 1302 ...    0    0    0]\n",
            " [8113 7050  803 ...    0    0    0]\n",
            " ...\n",
            " [8113   16 6773 ...    0    0    0]\n",
            " [8113   41    2 ...    0    0    0]\n",
            " [8113  419  104 ...    0    0    0]], shape=(128, 35), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205  368   75 ...    0    0    0]\n",
            " [4205  341  731 ...    0    0    0]\n",
            " [4205   11   54 ...    0    0    0]\n",
            " ...\n",
            " [4205  604  980 ...    0    0    0]\n",
            " [4205   34   72 ...    0    0    0]\n",
            " [4205  167  244 ...    0    0    0]], shape=(128, 40), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_examples = [\n",
        "    (\"It is important.\", \"这很重要。\"),\n",
        "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
        "]\n",
        "pprint(demo_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GY4jTq0nWBd",
        "outputId": "7e1b175c-9542-43fa-dbb8-621269316d50"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('It is important.', '这很重要。'),\n",
            " ('The numbers speak for themselves.', '数字证明了一切。')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
        "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
        "))\n",
        "\n",
        "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
        "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
        "demo_dataset = demo_examples.map(tf_add_bos_eos)\\\n",
        "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
        "\n",
        "# 取出這個 demo dataset 裡唯一一個 batch\n",
        "inp, tar = next(iter(demo_dataset))\n",
        "print('inp:', inp)\n",
        "print('' * 10)\n",
        "print('tar:', tar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrdNMrOKnc9J",
        "outputId": "b7a76739-ccb3-4afe-fae2-fd64144a92f7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "\n",
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
        "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
        "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
        "d_model = 4\n",
        "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
        "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
        "\n",
        "emb_inp = embedding_layer_en(inp)\n",
        "emb_tar = embedding_layer_zh(tar)\n",
        "emb_inp, emb_tar\n",
        "\n",
        "#(2, 8, 4), 2 sentences, 8 tokens, 4 embedding dimensions.\n",
        "#Demo only here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g19vVT_Lnd5V",
        "outputId": "d45464e3-4c07-48d5-cbd9-3709bda7e332"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              " array([[[ 0.00705861,  0.02399151,  0.02293142, -0.0475842 ],\n",
              "         [-0.04411458, -0.00038325,  0.00594477, -0.04343385],\n",
              "         [ 0.03762481,  0.03483142, -0.02369453, -0.04633626],\n",
              "         [-0.01023328, -0.00546096,  0.01027508, -0.00366773],\n",
              "         [-0.02832199, -0.01499226, -0.03385713, -0.00205602],\n",
              "         [-0.00751213, -0.0216771 ,  0.01374518, -0.02185503],\n",
              "         [-0.00358454,  0.01250425,  0.00170225,  0.02667595],\n",
              "         [-0.00358454,  0.01250425,  0.00170225,  0.02667595]],\n",
              " \n",
              "        [[ 0.00705861,  0.02399151,  0.02293142, -0.0475842 ],\n",
              "         [ 0.03000072, -0.03655797, -0.00418676, -0.00976621],\n",
              "         [ 0.02521231,  0.00669974, -0.03841607, -0.02963511],\n",
              "         [ 0.00166204, -0.00264503, -0.01186123, -0.03931201],\n",
              "         [-0.00076602,  0.03792257, -0.04935011,  0.0392368 ],\n",
              "         [ 0.0290105 , -0.01027643, -0.03418756,  0.03825184],\n",
              "         [-0.02832199, -0.01499226, -0.03385713, -0.00205602],\n",
              "         [-0.00751213, -0.0216771 ,  0.01374518, -0.02185503]]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
              " array([[[ 0.0374482 , -0.00984875, -0.04470841,  0.03143275],\n",
              "         [ 0.00077335,  0.04259989, -0.02596315,  0.01691676],\n",
              "         [ 0.0431367 ,  0.02816347,  0.04026764, -0.02475648],\n",
              "         [-0.00677568,  0.01504434, -0.02329274,  0.04708347],\n",
              "         [-0.03419787,  0.03714881, -0.01966884, -0.02002821],\n",
              "         [ 0.01031874, -0.00779353, -0.01892043, -0.04109555],\n",
              "         [-0.0001852 ,  0.03810075, -0.02871894,  0.03364593],\n",
              "         [ 0.04720506, -0.03792242, -0.03236812,  0.0158652 ],\n",
              "         [ 0.04720506, -0.03792242, -0.03236812,  0.0158652 ],\n",
              "         [ 0.04720506, -0.03792242, -0.03236812,  0.0158652 ]],\n",
              " \n",
              "        [[ 0.0374482 , -0.00984875, -0.04470841,  0.03143275],\n",
              "         [ 0.04191557, -0.04013853, -0.01336455,  0.02593288],\n",
              "         [-0.04463717,  0.01089229,  0.04534533, -0.01965655],\n",
              "         [-0.03494795,  0.00589152,  0.00134631, -0.01248996],\n",
              "         [-0.03090152, -0.03011897,  0.03860015, -0.00958091],\n",
              "         [ 0.03995107,  0.0194921 , -0.0348011 ,  0.01282269],\n",
              "         [ 0.03258323,  0.01311811, -0.00103819, -0.01426166],\n",
              "         [ 0.00746883,  0.03977631,  0.00604514, -0.01329761],\n",
              "         [ 0.01031874, -0.00779353, -0.01892043, -0.04109555],\n",
              "         [-0.0001852 ,  0.03810075, -0.02871894,  0.03364593]]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention\n",
        "1. Embedding as input\n",
        "2. padding mask and look ahead mask\n",
        "3. Self attention q,k,v\n",
        "4. Split heads\n",
        "5. Customized the self attention layers"
      ],
      "metadata": {
        "id": "J8abWyXMiosN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "inp_mask = create_padding_mask(inp)\n",
        "inp_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQhBT7xobi1",
        "outputId": "2cd2c398-6713-4785-f0fb-6d1a6131df3b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 1, 8), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tf.squeeze(inp_mask):\", tf.squeeze(inp_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlbEMTQxo0zn",
        "outputId": "174b824c-2d4b-4870-93bb-cd74d8b03924"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "tf.squeeze(inp_mask): tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
        "tf.random.set_seed(9527)\n",
        "\n",
        "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
        "q = emb_inp\n",
        "k = emb_inp\n",
        "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
        "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEU9Rv6Uo6kD",
        "outputId": "2d9558b8-78b0-4dac-b242-d1945f68bca7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.]],\n",
              "\n",
              "       [[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "  # 將 `q`、 `k` 做點積再 scale\n",
        "  # 2D np.dot = tf.matmul\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
        "\n",
        "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "  # in this case, scaled_attention_logits a tensor with size of (2,8,8) and mask size of (2,1,8), the mask would atuo expand to (2,8,8). It's broadcasting\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # 以注意權重對 v 做加權平均（weighted average）\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "metadata": {
        "id": "BCwhyenso7uy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = None\n",
        "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"output:\", output)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights:\", attention_weights)\n",
        "\n",
        "#the shape of out still remain (2,8,4). 2 sentences, 8 token long for each sentence and embedding dimension 4. But right now, it has the context and was distilled to a abstract concept of language."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE3PR6MCo-7Q",
        "outputId": "b77dc7e1-5da1-4d53-bea7-2f298f67d56e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: tf.Tensor(\n",
            "[[[0.3750108  0.37496844 0.37473753 0.50009507]\n",
            "  [0.37506366 0.3750978  0.37488383 0.50005436]\n",
            "  [0.37497973 0.37482017 0.37474605 0.50011766]\n",
            "  [0.37501413 0.37504452 0.3749942  0.49999842]\n",
            "  [0.37503392 0.37503952 0.37509888 0.49998748]\n",
            "  [0.3750372  0.37506497 0.37493807 0.500028  ]\n",
            "  [0.37497413 0.37499607 0.3750891  0.49995285]\n",
            "  [0.37497413 0.37499607 0.3750891  0.49995285]]\n",
            "\n",
            " [[0.62516737 0.24969853 0.625162   0.3749095 ]\n",
            "  [0.6251472  0.24990802 0.6251323  0.3748613 ]\n",
            "  [0.62512153 0.24997795 0.6249184  0.3749646 ]\n",
            "  [0.6250981  0.24979803 0.6250416  0.37485874]\n",
            "  [0.6248161  0.25046355 0.6246087  0.37530833]\n",
            "  [0.6249678  0.25034022 0.6248339  0.3751464 ]\n",
            "  [0.6248709  0.25003788 0.6248441  0.37493402]\n",
            "  [0.6250578  0.2497766  0.62514585 0.37482792]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "attention_weights: tf.Tensor(\n",
            "[[[0.12516744 0.12507154 0.1251266  0.1249668  0.12487654 0.12500274\n",
            "   0.12489418 0.12489418]\n",
            "  [0.12506181 0.12518603 0.12495655 0.12498626 0.12501559 0.1250298\n",
            "   0.12488199 0.12488199]\n",
            "  [0.12513629 0.12497595 0.12529747 0.12492301 0.12492043 0.12494163\n",
            "   0.1249026  0.1249026 ]\n",
            "  [0.12500739 0.12503658 0.12495391 0.1250103  0.12499642 0.12502049\n",
            "   0.12498746 0.12498746]\n",
            "  [0.12491369 0.12506251 0.12494791 0.12499301 0.1251272  0.12499838\n",
            "   0.12497865 0.12497865]\n",
            "  [0.12503386 0.12507066 0.12496306 0.12501101 0.1249923  0.12505955\n",
            "   0.12493476 0.12493476]\n",
            "  [0.12495803 0.12495556 0.12495677 0.12501074 0.12500535 0.12496752\n",
            "   0.125073   0.125073  ]\n",
            "  [0.12495803 0.12495556 0.12495677 0.12501074 0.12500535 0.12496752\n",
            "   0.125073   0.125073  ]]\n",
            "\n",
            " [[0.12521096 0.12497877 0.12505156 0.12509403 0.12486649 0.12483205\n",
            "   0.12491995 0.1250462 ]\n",
            "  [0.12495327 0.1251187  0.12503192 0.12500806 0.12487274 0.12503527\n",
            "   0.12496307 0.12501699]\n",
            "  [0.12498665 0.12499251 0.12512212 0.12503521 0.1249929  0.12498505\n",
            "   0.12496661 0.12491899]\n",
            "  [0.12506072 0.1250003  0.12506686 0.12507005 0.1248979  0.12490014\n",
            "   0.12499373 0.12501034]\n",
            "  [0.1248448  0.12487654 0.12503609 0.12490948 0.12531435 0.1251492\n",
            "   0.12504081 0.12482871]\n",
            "  [0.12480617 0.12503487 0.12502405 0.12490749 0.12514499 0.12519524\n",
            "   0.12499709 0.12489013]\n",
            "  [0.12489614 0.12496474 0.12500766 0.12500316 0.12503868 0.12499919\n",
            "   0.12510961 0.12498081]\n",
            "  [0.12505132 0.12504761 0.12498898 0.12504874 0.12485549 0.12492112\n",
            "   0.12500975 0.125077  ]]], shape=(2, 8, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 這次讓我們將 padding mask 放入注意函式並觀察\n",
        "# 注意權重的變化\n",
        "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
        "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"attention_weights:\", attention_weights)\n",
        "\n",
        "#the shape of out still remain (2,8,4). 2 sentences, 8 token long for each sentence and embedding dimension 4. But right now, it has the context and was distilled to a abstract concept of language."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3pdz1YpayS",
        "outputId": "6a5f9595-0ef3-45fa-9640-9487fb5f72ac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[0.16684283 0.166715   0.1667884  0.16657539 0.16645508 0.16662328\n",
            "   0.         0.        ]\n",
            "  [0.16669662 0.16686219 0.16655631 0.16659592 0.16663499 0.16665396\n",
            "   0.         0.        ]\n",
            "  [0.16680507 0.16659135 0.16701993 0.16652077 0.16651732 0.1665456\n",
            "   0.         0.        ]\n",
            "  [0.16667093 0.16670986 0.16659965 0.16667482 0.16665632 0.16668841\n",
            "   0.         0.        ]\n",
            "  [0.16654211 0.16674052 0.16658774 0.16664787 0.16682677 0.16665502\n",
            "   0.         0.        ]\n",
            "  [0.16668281 0.16673188 0.16658844 0.16665237 0.16662742 0.16671705\n",
            "   0.         0.        ]\n",
            "  [0.16664316 0.16663985 0.16664147 0.16671346 0.16670625 0.16665582\n",
            "   0.         0.        ]\n",
            "  [0.16664316 0.16663985 0.16664147 0.16671346 0.16670625 0.16665582\n",
            "   0.         0.        ]]\n",
            "\n",
            " [[0.12521096 0.12497877 0.12505156 0.12509403 0.12486649 0.12483205\n",
            "   0.12491995 0.1250462 ]\n",
            "  [0.12495327 0.1251187  0.12503192 0.12500806 0.12487274 0.12503527\n",
            "   0.12496307 0.12501699]\n",
            "  [0.12498665 0.12499251 0.12512212 0.12503521 0.1249929  0.12498505\n",
            "   0.12496661 0.12491899]\n",
            "  [0.12506072 0.1250003  0.12506686 0.12507005 0.1248979  0.12490014\n",
            "   0.12499373 0.12501034]\n",
            "  [0.1248448  0.12487654 0.12503609 0.12490948 0.12531435 0.1251492\n",
            "   0.12504081 0.12482871]\n",
            "  [0.12480617 0.12503487 0.12502405 0.12490749 0.12514499 0.12519524\n",
            "   0.12499709 0.12489013]\n",
            "  [0.12489614 0.12496474 0.12500766 0.12500316 0.12503868 0.12499919\n",
            "   0.12510961 0.12498081]\n",
            "  [0.12505132 0.12504761 0.12498898 0.12504874 0.12485549 0.12492112\n",
            "   0.12500975 0.125077  ]]], shape=(2, 8, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 建立一個 2 維矩陣，維度為 (size, size)，\n",
        "# 其遮罩為一個右上角的三角形\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
        "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask\", look_ahead_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igmroCsKpfbs",
        "outputId": "8ababf65-e877-4fcc-d730-cb60a0514777"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[ 0.0374482  -0.00984875 -0.04470841  0.03143275]\n",
            "  [ 0.00077335  0.04259989 -0.02596315  0.01691676]\n",
            "  [ 0.0431367   0.02816347  0.04026764 -0.02475648]\n",
            "  [-0.00677568  0.01504434 -0.02329274  0.04708347]\n",
            "  [-0.03419787  0.03714881 -0.01966884 -0.02002821]\n",
            "  [ 0.01031874 -0.00779353 -0.01892043 -0.04109555]\n",
            "  [-0.0001852   0.03810075 -0.02871894  0.03364593]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]]\n",
            "\n",
            " [[ 0.0374482  -0.00984875 -0.04470841  0.03143275]\n",
            "  [ 0.04191557 -0.04013853 -0.01336455  0.02593288]\n",
            "  [-0.04463717  0.01089229  0.04534533 -0.01965655]\n",
            "  [-0.03494795  0.00589152  0.00134631 -0.01248996]\n",
            "  [-0.03090152 -0.03011897  0.03860015 -0.00958091]\n",
            "  [ 0.03995107  0.0194921  -0.0348011   0.01282269]\n",
            "  [ 0.03258323  0.01311811 -0.00103819 -0.01426166]\n",
            "  [ 0.00746883  0.03977631  0.00604514 -0.01329761]\n",
            "  [ 0.01031874 -0.00779353 -0.01892043 -0.04109555]\n",
            "  [-0.0001852   0.03810075 -0.02871894  0.03364593]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 讓我們用目標語言（中文）的 batch\n",
        "# 來模擬 Decoder 處理的情況\n",
        "temp_q = temp_k = emb_tar\n",
        "temp_v = tf.cast(tf.math.greater(\n",
        "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
        "\n",
        "# 將 look_ahead_mask 放入注意函式\n",
        "_, attention_weights = scaled_dot_product_attention(\n",
        "    temp_q, temp_k, temp_v, look_ahead_mask)\n",
        "\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVwnbxJ_pl2R",
        "outputId": "4ac6cf5d-6722-4522-bf76-32f213ba63e5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.4998158  0.50018424 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.3329367  0.33310476 0.33395854 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.25010183 0.25009152 0.2495907  0.25021595 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.19979538 0.20010778 0.19986247 0.19996552 0.20026888 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.16665342 0.16660799 0.16669208 0.16651194 0.16669804 0.16683657\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.1428911  0.14296101 0.14268522 0.14295313 0.1428449  0.14266996\n",
            "   0.14299466 0.         0.         0.        ]\n",
            "  [0.12520462 0.12491967 0.12490356 0.12498719 0.12478021 0.12499546\n",
            "   0.12494964 0.12525965 0.         0.        ]\n",
            "  [0.11126732 0.11101408 0.11099977 0.11107409 0.11089014 0.11108144\n",
            "   0.11104072 0.11131623 0.11131623 0.        ]\n",
            "  [0.10012211 0.09989423 0.09988135 0.09994823 0.09978271 0.09995484\n",
            "   0.0999182  0.10016611 0.10016611 0.10016611]]\n",
            "\n",
            " [[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.4998948  0.50010514 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.3327788  0.33294523 0.33427593 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.24978875 0.24976079 0.25025755 0.2501929  0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.19963604 0.19983947 0.20022358 0.20003189 0.20026903 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.16693686 0.1668056  0.16638155 0.16654074 0.16639097 0.16694425\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.14289868 0.14288396 0.14277245 0.14278626 0.14275624 0.14295024\n",
            "   0.1429522  0.         0.         0.        ]\n",
            "  [0.12494452 0.12488776 0.12503424 0.12500376 0.12492779 0.12503783\n",
            "   0.12505382 0.12511028 0.         0.        ]\n",
            "  [0.11109565 0.11109094 0.11106161 0.11109921 0.11107132 0.11111645\n",
            "   0.11114135 0.11110575 0.11121774 0.        ]\n",
            "  [0.10008442 0.09997237 0.09990943 0.09997501 0.09985787 0.10009476\n",
            "   0.09998859 0.10003107 0.09992952 0.10015696]]], shape=(2, 10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multi-head split the demension of embedding, process them seperately\n",
        "\n",
        "def split_heads(x, d_model, num_heads):\n",
        "  # x.shape: (batch_size, seq_len, d_model)\n",
        "  batch_size = tf.shape(x)[0]\n",
        "\n",
        "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
        "  assert d_model % num_heads == 0\n",
        "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度\n",
        "\n",
        "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
        "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
        "  # fill in the rest to -1 dimenstion\n",
        "  # (batch_size, seq_len, num_heads, depth)\n",
        "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
        "\n",
        "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
        "  # change the sequence of dimension for better understanding.\n",
        "  # (batch_size, num_heads, seq_len, depth)\n",
        "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  return output\n",
        "\n",
        "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
        "d_model = 4\n",
        "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
        "num_heads = 2\n",
        "x = emb_inp\n",
        "\n",
        "output = split_heads(x, d_model, num_heads)\n",
        "print(\"x:\", x)\n",
        "print(\"output:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAq54KzbpmrA",
        "outputId": "d75adf48-e402-4985-9e9b-e7127291aa32"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tf.Tensor(\n",
            "[[[ 0.00705861  0.02399151  0.02293142 -0.0475842 ]\n",
            "  [-0.04411458 -0.00038325  0.00594477 -0.04343385]\n",
            "  [ 0.03762481  0.03483142 -0.02369453 -0.04633626]\n",
            "  [-0.01023328 -0.00546096  0.01027508 -0.00366773]\n",
            "  [-0.02832199 -0.01499226 -0.03385713 -0.00205602]\n",
            "  [-0.00751213 -0.0216771   0.01374518 -0.02185503]\n",
            "  [-0.00358454  0.01250425  0.00170225  0.02667595]\n",
            "  [-0.00358454  0.01250425  0.00170225  0.02667595]]\n",
            "\n",
            " [[ 0.00705861  0.02399151  0.02293142 -0.0475842 ]\n",
            "  [ 0.03000072 -0.03655797 -0.00418676 -0.00976621]\n",
            "  [ 0.02521231  0.00669974 -0.03841607 -0.02963511]\n",
            "  [ 0.00166204 -0.00264503 -0.01186123 -0.03931201]\n",
            "  [-0.00076602  0.03792257 -0.04935011  0.0392368 ]\n",
            "  [ 0.0290105  -0.01027643 -0.03418756  0.03825184]\n",
            "  [-0.02832199 -0.01499226 -0.03385713 -0.00205602]\n",
            "  [-0.00751213 -0.0216771   0.01374518 -0.02185503]]], shape=(2, 8, 4), dtype=float32)\n",
            "output: tf.Tensor(\n",
            "[[[[ 0.00705861  0.02399151]\n",
            "   [-0.04411458 -0.00038325]\n",
            "   [ 0.03762481  0.03483142]\n",
            "   [-0.01023328 -0.00546096]\n",
            "   [-0.02832199 -0.01499226]\n",
            "   [-0.00751213 -0.0216771 ]\n",
            "   [-0.00358454  0.01250425]\n",
            "   [-0.00358454  0.01250425]]\n",
            "\n",
            "  [[ 0.02293142 -0.0475842 ]\n",
            "   [ 0.00594477 -0.04343385]\n",
            "   [-0.02369453 -0.04633626]\n",
            "   [ 0.01027508 -0.00366773]\n",
            "   [-0.03385713 -0.00205602]\n",
            "   [ 0.01374518 -0.02185503]\n",
            "   [ 0.00170225  0.02667595]\n",
            "   [ 0.00170225  0.02667595]]]\n",
            "\n",
            "\n",
            " [[[ 0.00705861  0.02399151]\n",
            "   [ 0.03000072 -0.03655797]\n",
            "   [ 0.02521231  0.00669974]\n",
            "   [ 0.00166204 -0.00264503]\n",
            "   [-0.00076602  0.03792257]\n",
            "   [ 0.0290105  -0.01027643]\n",
            "   [-0.02832199 -0.01499226]\n",
            "   [-0.00751213 -0.0216771 ]]\n",
            "\n",
            "  [[ 0.02293142 -0.0475842 ]\n",
            "   [-0.00418676 -0.00976621]\n",
            "   [-0.03841607 -0.02963511]\n",
            "   [-0.01186123 -0.03931201]\n",
            "   [-0.04935011  0.0392368 ]\n",
            "   [-0.03418756  0.03825184]\n",
            "   [-0.03385713 -0.00205602]\n",
            "   [ 0.01374518 -0.02185503]]]], shape=(2, 2, 8, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a multi-head attention layer by inheriting tf.keras.layers.Layer\n",
        "# initialize by dimension of model\n",
        "# initialize q, k, v using tf.keras.layers.Dense\n",
        "# ouput a attension result and attension weights matrix\n",
        "# output.shape = (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape = (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super().__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0  #make sure dimenstions of embedding can be divided.\n",
        "\n",
        "    self.depth = d_model // self.num_heads  #depth in every head\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # input of q matual wq.\n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # No activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # for combining mutiple heads.\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0] #number of examples\n",
        "\n",
        "    # project q, k, v to embedding dimensions for example (2,8,4). 2 sentences, 8 tokens, 4 dimensions\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    # split heads from (2,8,4) to (2,2,8,2)\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    #pass q, k, v and mask to self attention.\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "    # Reverse the process of splitting heads.\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # final layer\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "wb57O1-mpt8J"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb_inp.shape = (batch_size, seq_len, d_model) = (2, 8, 4)\n",
        "assert d_model == emb_inp.shape[-1]  == 4\n",
        "num_heads = 2\n",
        "\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"num_heads: {num_heads}\\n\")\n",
        "\n",
        "# 初始化一個 multi-head attention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# set v = k = q = embedded examples (2,8,4), 2 examples, 8 tokens, and 4 dimensions of embedding.\n",
        "# shape of inp: (2,8) shape of imp_inp = (2,8,4)\n",
        "# padding mask\n",
        "# The last tokens of en embedding is <pad>\n",
        "v = k = q = emb_inp\n",
        "padding_mask = create_padding_mask(inp)\n",
        "print(\"q.shape:\", q.shape)\n",
        "print(\"k.shape:\", k.shape)\n",
        "print(\"v.shape:\", v.shape)\n",
        "print(\"padding_mask.shape:\", padding_mask.shape)\n",
        "\n",
        "output, attention_weights = mha(v, k, q, padding_mask)\n",
        "print(\"output.shape:\", output.shape)\n",
        "print(\"attention_weights.shape:\", attention_weights.shape) # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "print(\"\\noutput:\", output)\n",
        "\n",
        "# attention_weights.shape: (2, 2, 8, 8): 2 batches, 2 heads, 8 words (attention: 8x8)\n",
        "# mask shape=(2, 1, 8)\n",
        "# it's a demonstration with 2 sentences as inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlaUvaTPp0Iy",
        "outputId": "af87856c-d436-4ee9-d7ec-049e03689cab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_model: 4\n",
            "num_heads: 2\n",
            "\n",
            "q.shape: (2, 8, 4)\n",
            "k.shape: (2, 8, 4)\n",
            "v.shape: (2, 8, 4)\n",
            "padding_mask.shape: (2, 1, 1, 8)\n",
            "output.shape: (2, 8, 4)\n",
            "attention_weights.shape: (2, 2, 8, 8)\n",
            "\n",
            "output: tf.Tensor(\n",
            "[[[ 0.00431892 -0.00328365  0.02393488 -0.02875126]\n",
            "  [ 0.00431417 -0.00329426  0.02393649 -0.02876165]\n",
            "  [ 0.0043129  -0.00328853  0.02393563 -0.02875527]\n",
            "  [ 0.00430119 -0.00330292  0.02394037 -0.02877015]\n",
            "  [ 0.0042945  -0.00331329  0.02394181 -0.02877979]\n",
            "  [ 0.00430283 -0.00330294  0.02393851 -0.02876927]\n",
            "  [ 0.00429553 -0.00330572  0.02394353 -0.02877386]\n",
            "  [ 0.00429553 -0.00330572  0.02394353 -0.02877386]]\n",
            "\n",
            " [[-0.01293799 -0.01017688  0.01152695 -0.02628573]\n",
            "  [-0.01296034 -0.01021318  0.01157479 -0.02631518]\n",
            "  [-0.01295135 -0.01019915  0.01155651 -0.02630412]\n",
            "  [-0.01294464 -0.01019161  0.01154747 -0.02629979]\n",
            "  [-0.01295988 -0.01021008  0.01155863 -0.02630562]\n",
            "  [-0.01296998 -0.01022517  0.01158257 -0.02631941]\n",
            "  [-0.01295135 -0.01020615  0.01156182 -0.02631061]\n",
            "  [-0.01294809 -0.01019742  0.01155334 -0.02630368]]], shape=(2, 8, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building\n",
        "1. Define the feed foward layer after attension\n",
        "2. Define the Encoder layer\n",
        "3. Define positional encoding layer\n",
        "4. Stack up the encoder\n",
        "5. repeat steps above, build up a decoder, only the decoder has two layers of mha\n",
        "6. combine encoder layers and decoder layers into transformer.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTExr5wnOfqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed foward layer after attention layer.\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  #d_model: demensions of the embedding\n",
        "  #dff neurons in the middle layer.\n",
        "\n",
        "  # relu in the middle layer: FNN with one layer.\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "metadata": {
        "id": "ANM7EzhVOkGc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "seq_len = 10\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "\n",
        "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "out = ffn(x)\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"out.shape:\", out.shape)\n",
        "\n",
        "#64 examples, 10 tokens, 512 dimensions of embeddin."
      ],
      "metadata": {
        "id": "h5j9VHYVYG2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a151b4e-7adc-4766-b8bd-2505b7e0d1bd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: (64, 10, 512)\n",
            "out.shape: (64, 10, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 4 # FFN 的輸入輸出張量的最後一維皆為 `d_model`\n",
        "dff = 6\n",
        "\n",
        "# 建立一個小 FFN\n",
        "small_ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "# 懂子詞梗的站出來\n",
        "dummy_sentence = tf.constant([[5, 5, 6, 6],\n",
        "                              [5, 5, 6, 6],\n",
        "                              [9, 5, 2, 7],\n",
        "                              [9, 5, 2, 7],\n",
        "                              [9, 5, 2, 7]], dtype=tf.float32)\n",
        "small_ffn(dummy_sentence)"
      ],
      "metadata": {
        "id": "PZMQbLsttkZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8f9a7c-e158-4e5c-d951-fc44c9fec188"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[-0.8580706 , -2.285285  ,  2.5645552 ,  2.628685  ],\n",
              "       [-0.8580706 , -2.285285  ,  2.5645552 ,  2.628685  ],\n",
              "       [ 0.05360652, -0.94552475,  2.6374204 ,  0.9469749 ],\n",
              "       [ 0.05360652, -0.94552475,  2.6374204 ,  0.9469749 ],\n",
              "       [ 0.05360652, -0.94552475,  2.6374204 ,  0.9469749 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An encoder incoperates 2 sub-layers: MHA & FFN\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  # Default dropout rate is 0.1\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # layer normalization to normalized the attention from a sentence.\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    # One layer should have one dropout layer\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  # training argument to decide whether on training or not.\n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    # x is embedding + positional encoding with shape (batch_size, input_seq_len, d_model)\n",
        "    # attn shape = (batch_size, num_heads, input_seq_len, input_seq_len)\n",
        "    # sub-layer 1: MHA\n",
        "    # set q, k, v as x\n",
        "    # padding mask to mask <pad>\n",
        "    attn_output, attn = self.mha(x, x, x, mask)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "    # sub-layer 2: FFN\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)  # 記得 training\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "    return out2"
      ],
      "metadata": {
        "id": "hdAlg4mrYRZt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
        "padding_mask = create_padding_mask(inp) #inp = (2,8), 2 examples, 8 tokens\n",
        "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"padding_mask:\", padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_inp:\", emb_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "assert emb_inp.shape == enc_out.shape\n",
        "\n",
        "#encoder needs only padding mask. Input a whole sentence of English (inp: (2,8)), transfer it using embedding (emb_inp: (2,8,4)), and transfer it to a vector of represent (enc_out, (2,8,4))\n",
        "#And the vector that incorperates the meaning of the sentence would diliver it to the decoder\n",
        "#Shape of enc_out = (2,8,4), (batch_size, seq_len_q, num_heads * depth). 2 examples, 8 sums of attentions by each token to other tokens in the sentences, attentions from mutiheads."
      ],
      "metadata": {
        "id": "Z_aNbMCGbcRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7820ae2c-6bc6-4474-f7f6-37389bbd4f4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "emb_inp: tf.Tensor(\n",
            "[[[ 0.00705861  0.02399151  0.02293142 -0.0475842 ]\n",
            "  [-0.04411458 -0.00038325  0.00594477 -0.04343385]\n",
            "  [ 0.03762481  0.03483142 -0.02369453 -0.04633626]\n",
            "  [-0.01023328 -0.00546096  0.01027508 -0.00366773]\n",
            "  [-0.02832199 -0.01499226 -0.03385713 -0.00205602]\n",
            "  [-0.00751213 -0.0216771   0.01374518 -0.02185503]\n",
            "  [-0.00358454  0.01250425  0.00170225  0.02667595]\n",
            "  [-0.00358454  0.01250425  0.00170225  0.02667595]]\n",
            "\n",
            " [[ 0.00705861  0.02399151  0.02293142 -0.0475842 ]\n",
            "  [ 0.03000072 -0.03655797 -0.00418676 -0.00976621]\n",
            "  [ 0.02521231  0.00669974 -0.03841607 -0.02963511]\n",
            "  [ 0.00166204 -0.00264503 -0.01186123 -0.03931201]\n",
            "  [-0.00076602  0.03792257 -0.04935011  0.0392368 ]\n",
            "  [ 0.0290105  -0.01027643 -0.03418756  0.03825184]\n",
            "  [-0.02832199 -0.01499226 -0.03385713 -0.00205602]\n",
            "  [-0.00751213 -0.0216771   0.01374518 -0.02185503]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.34667647  1.6899221  -0.42482796 -0.91841775]\n",
            "  [-1.3690498   1.4432445   0.10430922 -0.17850392]\n",
            "  [ 0.37170863  1.4271919  -1.221111   -0.57778955]\n",
            "  [-1.5297706   1.2559996  -0.01276144  0.28653252]\n",
            "  [-0.76926136  1.1699368  -1.1900877   0.78941214]\n",
            "  [-1.2857637  -0.16956615  1.5210826  -0.0657528 ]\n",
            "  [-1.0617033   1.1180228  -0.92849857  0.87217903]\n",
            "  [-1.0617033   1.1180228  -0.92849857  0.87217903]]\n",
            "\n",
            " [[ 0.7257246   1.1649609  -0.53986704 -1.3508185 ]\n",
            "  [ 1.5331161  -1.2538377  -0.27828097 -0.00099742]\n",
            "  [ 0.9941485   0.7001654  -1.5840708  -0.11024311]\n",
            "  [ 1.3822701   0.49683934 -1.135701   -0.7434085 ]\n",
            "  [-0.13344516  1.0159953  -1.5727555   0.6902054 ]\n",
            "  [ 0.72998756 -0.40702742 -1.4360963   1.113136  ]\n",
            "  [-0.00001015  0.3446857  -1.5546886   1.2100132 ]\n",
            "  [ 0.9034356  -1.3748792   1.0046085  -0.533165  ]]], shape=(2, 8, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# postitional encoding\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "\n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "d_model = 512\n",
        "\n",
        "pos_encoding = positional_encoding(seq_len, d_model)\n",
        "pos_encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x-cXWLCUsys",
        "outputId": "f98fc99f-6899-4171-c663-1d1f1669b809"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
              "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        ...,\n",
              "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
              "          0.99998724,  0.99998814],\n",
              "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
              "          0.9999867 ,  0.9999876 ],\n",
              "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
              "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  # An encoder incorperates embedding layer, postional encoding layer, layers of encoder layer\n",
        "  # num_layers: layers of encoder layer\n",
        "  # input_vocab_size: size of dictionary\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "          rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "\n",
        "    # How many encoder layers in a list.\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "               for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "    # x.shape == (batch_size, input_seq_len)\n",
        "    # output of following layers (batch_size, input_seq_len, d_model)\n",
        "    input_seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # embedding + regularization + postional encoding + dropout\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :input_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    # N layers of encoder layer\n",
        "    for enc_layer in self.enc_layers:\n",
        "      x = enc_layer(x, training, mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DfjrENUfU8xy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "num_layers = 2 # encoder with 2 layers of encoder layer\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2 # size of en dictionary + 2 (<BOS> and <EOS>)\n",
        "\n",
        "# Initialize an encoder\n",
        "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "\n",
        "# it's a demo, inp = (2,8)\n",
        "enc_out = encoder(inp, training=False, mask=None)\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNV06agNXLTz",
        "outputId": "bbdc0c16-9846-4654-e74f-ed285ed3ef70"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[ 0.8493257  -0.7559991  -1.20915     1.1158235 ]\n",
            "  [ 1.3490521  -0.594244   -1.2554873   0.5006793 ]\n",
            "  [ 1.3348391  -0.3584769  -1.3862493   0.409887  ]\n",
            "  [ 0.87244916  0.0236648  -1.639014    0.7429    ]\n",
            "  [ 0.60081315  0.11165629 -1.6548388   0.94236934]\n",
            "  [ 0.6161901  -0.19738793 -1.5310751   1.1122729 ]\n",
            "  [ 0.7751993  -0.70389163 -1.2400323   1.1687247 ]\n",
            "  [ 1.2637944  -0.80681306 -1.1360853   0.67910385]]\n",
            "\n",
            " [[ 0.86102414 -0.7728823  -1.1967638   1.1086218 ]\n",
            "  [ 1.3225126  -0.64340585 -1.2357653   0.5566586 ]\n",
            "  [ 1.3137655  -0.37113506 -1.3910974   0.4484671 ]\n",
            "  [ 0.95557445 -0.02194843 -1.6180216   0.6843955 ]\n",
            "  [ 0.62594616  0.10492884 -1.6558032   0.924928  ]\n",
            "  [ 0.5681132  -0.1117382  -1.5624695   1.1060946 ]\n",
            "  [ 0.7309585  -0.64072996 -1.2802435   1.190015  ]\n",
            "  [ 1.305046   -0.743744   -1.1712029   0.609901  ]]], shape=(2, 8, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder incorperates N DecoderLayer，\n",
        "# and DecoderLayer has 3 sub-layers: self attention MHA, attention of Encoder MHA and FFN\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    # 3 types of sublayer in the decoder layer\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # LayerNorm for every sub layer\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    # drop for every sub-layer\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           combined_mask, inp_padding_mask):\n",
        "    # shape of output of all sublayers are (batch_size, target_seq_len, d_model)\n",
        "    # enc_output is the ouput of Encoder with shape (batch_size, input_seq_len, d_model)\n",
        "    # shape of attn_weights_block_1: (batch_size, num_heads, target_seq_len, target_seq_len)\n",
        "    # shape of attn_weights_block_2: (batch_size, num_heads, target_seq_len, input_seq_len)\n",
        "\n",
        "    # sub-layer 1: Decoder layer, self attention of the decoder input\n",
        "    # Need look ahead mask and padding mask: conbined_mask\n",
        "    # x: cn input. tokens before the next one\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    # sub-layer 2: Decoder layer: attention of encoder.\n",
        "    # Need padding mask only.\n",
        "    attn2, attn_weights_block2 = self.mha2(enc_output, enc_output,\n",
        "                          out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    # sub-layer 3: FFN\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "id": "zlsCOMSdesbB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "# stack up two masks for decoder\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_padding_mask:\", tar_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask:\", look_ahead_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)"
      ],
      "metadata": {
        "id": "GmV8g4AGgOPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bbfaba-6ce9-4d11-9f6d-bf1da0aa6201"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask: tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
        "\n",
        "# Both inp and tar (en for encoder and ch for decoder) need padding mask\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "\n",
        "# lood ahead mask + padding mask for target input.\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# enc_out from encoder. emb_tar hasn't applying positional encoding yet.\n",
        "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
        "                                     emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_out:\", dec_out)\n",
        "assert emb_tar.shape == dec_out.shape\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
        "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)\n",
        "\n",
        "\n",
        "#shape of emb_tar: (2, 10, 4). 2 examples, 10 tokens, 4 embedding dimensions of zh embedding\n",
        "#shape of enc_out: (2, 8, 4). 2 examples, 8 tokens, 4 embedding dimensions of en embedding\n",
        "#shape of dec_out: (2, 10 , 4). 2 examples, 8 sums of attention from other tokens, 2 heads * 2 depth (multi heads)\n",
        "#shape of dec_self_attn_weights (2, 2, 10, 10): 2 examples, 2 heads. 10 x 10 attentions. 10 tokens and their attentions on each others\n",
        "#shape of dec_enc_attn_weights (2, 2, 10, 8): 2 examples, 2 heads, 10 x 8 attentions. 10 tokens and their attentions on encoder."
      ],
      "metadata": {
        "id": "LzSV1u4AgQWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f42097-9637-47c6-95ae-87d5dc62d4b7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[ 0.0374482  -0.00984875 -0.04470841  0.03143275]\n",
            "  [ 0.00077335  0.04259989 -0.02596315  0.01691676]\n",
            "  [ 0.0431367   0.02816347  0.04026764 -0.02475648]\n",
            "  [-0.00677568  0.01504434 -0.02329274  0.04708347]\n",
            "  [-0.03419787  0.03714881 -0.01966884 -0.02002821]\n",
            "  [ 0.01031874 -0.00779353 -0.01892043 -0.04109555]\n",
            "  [-0.0001852   0.03810075 -0.02871894  0.03364593]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]\n",
            "  [ 0.04720506 -0.03792242 -0.03236812  0.0158652 ]]\n",
            "\n",
            " [[ 0.0374482  -0.00984875 -0.04470841  0.03143275]\n",
            "  [ 0.04191557 -0.04013853 -0.01336455  0.02593288]\n",
            "  [-0.04463717  0.01089229  0.04534533 -0.01965655]\n",
            "  [-0.03494795  0.00589152  0.00134631 -0.01248996]\n",
            "  [-0.03090152 -0.03011897  0.03860015 -0.00958091]\n",
            "  [ 0.03995107  0.0194921  -0.0348011   0.01282269]\n",
            "  [ 0.03258323  0.01311811 -0.00103819 -0.01426166]\n",
            "  [ 0.00746883  0.03977631  0.00604514 -0.01329761]\n",
            "  [ 0.01031874 -0.00779353 -0.01892043 -0.04109555]\n",
            "  [-0.0001852   0.03810075 -0.02871894  0.03364593]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[ 0.8493257  -0.7559991  -1.20915     1.1158235 ]\n",
            "  [ 1.3490521  -0.594244   -1.2554873   0.5006793 ]\n",
            "  [ 1.3348391  -0.3584769  -1.3862493   0.409887  ]\n",
            "  [ 0.87244916  0.0236648  -1.639014    0.7429    ]\n",
            "  [ 0.60081315  0.11165629 -1.6548388   0.94236934]\n",
            "  [ 0.6161901  -0.19738793 -1.5310751   1.1122729 ]\n",
            "  [ 0.7751993  -0.70389163 -1.2400323   1.1687247 ]\n",
            "  [ 1.2637944  -0.80681306 -1.1360853   0.67910385]]\n",
            "\n",
            " [[ 0.86102414 -0.7728823  -1.1967638   1.1086218 ]\n",
            "  [ 1.3225126  -0.64340585 -1.2357653   0.5566586 ]\n",
            "  [ 1.3137655  -0.37113506 -1.3910974   0.4484671 ]\n",
            "  [ 0.95557445 -0.02194843 -1.6180216   0.6843955 ]\n",
            "  [ 0.62594616  0.10492884 -1.6558032   0.924928  ]\n",
            "  [ 0.5681132  -0.1117382  -1.5624695   1.1060946 ]\n",
            "  [ 0.7309585  -0.64072996 -1.2802435   1.190015  ]\n",
            "  [ 1.305046   -0.743744   -1.1712029   0.609901  ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[ 0.05510411 -0.4304319  -1.1800447   1.5553725 ]\n",
            "  [-0.8029047   0.99350786 -1.1793029   0.9886997 ]\n",
            "  [ 0.5583818  -0.3868076   1.2415891  -1.4131633 ]\n",
            "  [-1.1611942   0.14706966 -0.52147365  1.5355983 ]\n",
            "  [-1.4917164   1.262675   -0.16314411  0.3921854 ]\n",
            "  [ 1.3869559   0.4404357  -0.587596   -1.2397958 ]\n",
            "  [-1.004647    0.864354   -0.9866723   1.1269653 ]\n",
            "  [ 0.07257253 -1.4779403   0.06124434  1.3441235 ]\n",
            "  [ 0.07257253 -1.4779403   0.06124434  1.3441235 ]\n",
            "  [ 0.07257253 -1.4779403   0.06124434  1.3441235 ]]\n",
            "\n",
            " [[-0.02095461 -0.4648131  -1.1109111   1.596679  ]\n",
            "  [-0.52097976 -1.2717446   0.39421117  1.3985133 ]\n",
            "  [-1.6520103   0.27544507  1.0400798   0.3364855 ]\n",
            "  [-1.7211541   0.6793266   0.39161113  0.6502164 ]\n",
            "  [-1.4892159   0.0232583   1.3276126   0.13834487]\n",
            "  [ 0.61887753  0.22459725 -1.6887848   0.84531   ]\n",
            "  [ 1.4348649   0.43142262 -0.85092926 -1.0153582 ]\n",
            "  [-0.6503167   1.7074449  -0.3017265  -0.7554016 ]\n",
            "  [ 1.4094027   0.4473391  -0.71656716 -1.1401746 ]\n",
            "  [-0.9266099   0.78229296 -1.0501149   1.1944318 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_self_attn_weights.shape: (2, 2, 10, 10)\n",
            "dec_enc_attn_weights: (2, 2, 10, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  #applying target_vocab_size as input\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "             rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    #cn dictionary as input\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "               for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           combined_mask, inp_padding_mask):\n",
        "\n",
        "    tar_seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}  #for attentions of decoder itself.\n",
        "\n",
        "    # same process as encoder.\n",
        "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i, dec_layer in enumerate(self.dec_layers):\n",
        "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
        "                        combined_mask, inp_padding_mask)\n",
        "\n",
        "      # save the weighting of attention layers of the decoder.\n",
        "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "\n",
        "    # x.shape = (batch_size, tar_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "metadata": {
        "id": "QQI2IiUXlaiY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "num_layers = 2 # 2 layers of decoder layers\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2 # cn dictionary + 2 (<BOS>,<EOS>)\n",
        "\n",
        "# decoder need both look ahead and padding\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# intial a decoder\n",
        "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "# it's an example, set input as tar (2,10)\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_padding_mask:\", inp_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "dec_out, attn = decoder(tar, enc_out, training=False,\n",
        "                        combined_mask=combined_mask,\n",
        "                        inp_padding_mask=inp_padding_mask)\n",
        "print(\"dec_out:\", dec_out)\n",
        "print(\"-\" * 20)\n",
        "for block_name, attn_weights in attn.items():\n",
        "  print(f\"{block_name}.shape: {attn_weights.shape}\")\n",
        "\n",
        "#shape of tar: (2, 10). 2 examples, 10 tokens\n",
        "#shape of enc_out: (2, 8, 4). 2 examples, 8 tokens, 4 embedding dimensions of en embedding\n",
        "#shape of dec_out: (2, 10, 4). 2 examples, 8 sums of attention from other tokens, 2 heads * 2 depth (multi heads)\n",
        "#shape of decoder_layer1_block1 (2, 2, 10, 10): 2 examples, 2 heads. 10 x 10 attentions. 10 tokens and their attentions on each others\n",
        "#shape of decoder_layer1_block2 (2, 2, 10, 8): 2 examples, 2 heads, 10 x 8 attentions. 10 tokens and their attentions on encoder.\n",
        "#shape of decoder_layer2_block1 (2, 2, 10, 10)\n",
        "#shape of decoder_layer2_block2 (2, 2, 10, 8)\n"
      ],
      "metadata": {
        "id": "fnNmeo21n0SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5949d6-b977-486a-ace9-d73b00641ed9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[ 0.8493257  -0.7559991  -1.20915     1.1158235 ]\n",
            "  [ 1.3490521  -0.594244   -1.2554873   0.5006793 ]\n",
            "  [ 1.3348391  -0.3584769  -1.3862493   0.409887  ]\n",
            "  [ 0.87244916  0.0236648  -1.639014    0.7429    ]\n",
            "  [ 0.60081315  0.11165629 -1.6548388   0.94236934]\n",
            "  [ 0.6161901  -0.19738793 -1.5310751   1.1122729 ]\n",
            "  [ 0.7751993  -0.70389163 -1.2400323   1.1687247 ]\n",
            "  [ 1.2637944  -0.80681306 -1.1360853   0.67910385]]\n",
            "\n",
            " [[ 0.86102414 -0.7728823  -1.1967638   1.1086218 ]\n",
            "  [ 1.3225126  -0.64340585 -1.2357653   0.5566586 ]\n",
            "  [ 1.3137655  -0.37113506 -1.3910974   0.4484671 ]\n",
            "  [ 0.95557445 -0.02194843 -1.6180216   0.6843955 ]\n",
            "  [ 0.62594616  0.10492884 -1.6558032   0.924928  ]\n",
            "  [ 0.5681132  -0.1117382  -1.5624695   1.1060946 ]\n",
            "  [ 0.7309585  -0.64072996 -1.2802435   1.190015  ]\n",
            "  [ 1.305046   -0.743744   -1.1712029   0.609901  ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "inp_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[ 1.0543623  -1.3376294  -0.5860145   0.8692817 ]\n",
            "  [ 1.399921   -1.3107557  -0.44343096  0.35426578]\n",
            "  [ 1.3605742  -1.2767612  -0.54944956  0.46563658]\n",
            "  [ 0.12717016 -1.0143356  -0.688101    1.5752665 ]\n",
            "  [-0.6297357  -0.19527276 -0.8573343   1.6823426 ]\n",
            "  [-1.0988662   0.11376937 -0.57851195  1.5636086 ]\n",
            "  [-0.8116784  -0.81451416 -0.0101573   1.6363498 ]\n",
            "  [ 0.7396317  -1.4787645  -0.33507472  1.0742075 ]\n",
            "  [ 1.1702248  -1.4190058  -0.41692588  0.6657068 ]\n",
            "  [ 0.6369284  -1.3356525  -0.53557956  1.2343037 ]]\n",
            "\n",
            " [[ 0.95049274 -1.3542001  -0.56665516  0.97036254]\n",
            "  [ 1.3585689  -1.3212572  -0.4702468   0.4329351 ]\n",
            "  [ 1.2321852  -1.3001881  -0.59405637  0.6620592 ]\n",
            "  [ 0.17436802 -1.11284    -0.6010009   1.539473  ]\n",
            "  [-0.6083319  -0.3595063  -0.74740744  1.7152458 ]\n",
            "  [-1.1455005   0.33543986 -0.6549717   1.4650325 ]\n",
            "  [-0.8779866  -0.775663    0.0330346   1.620615  ]\n",
            "  [ 1.0925378  -1.4655629  -0.35612375  0.72914904]\n",
            "  [ 1.2469072  -1.3852495  -0.43912637  0.57746863]\n",
            "  [ 0.58225924 -1.3223639  -0.5350574   1.275162  ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "decoder_layer1_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer1_block2.shape: (2, 2, 10, 8)\n",
            "decoder_layer2_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer2_block2.shape: (2, 2, 10, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inherited from tf.keras.Model\n",
        "class Transformer(tf.keras.Model):\n",
        "  # arguments comprise argements of encoder, decoder and size of both en and ch dictionary.\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               target_vocab_size, rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                target_vocab_size, rate)\n",
        "    # the size of ffn is euqal to ch dictionary. So when passing through softmax layer, it would generate the probability of each tokens.\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  # enc_padding_mask and dec_padding_mask are both padding mask generated from en，\n",
        "  # One is for Encoder layer's MHA and the other is for Decoder layer's MHA 2\n",
        "  def call(self, inp, tar, training, enc_padding_mask,\n",
        "           combined_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape = (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(tar, enc_output, training,\n",
        "                            combined_mask, dec_padding_mask)\n",
        "\n",
        "    # last fnn layer before softmax.\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights"
      ],
      "metadata": {
        "id": "OsSlGoPun3ag"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar[:,:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLE1rjNOesD6",
        "outputId": "83f7a11e-88cd-4f15-e2a4-bcd8005750f6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 9), dtype=int64, numpy=\n",
              "array([[4205,   10,  241,   86,   27,    3, 4206,    0,    0],\n",
              "       [4205,  165,  489,  398,  191,   14,    7,  560,    3]])>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter\n",
        "num_layers = 1\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# + 2 for <BOS> & <EOS> token\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
        "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# For predicting next word.\n",
        "# size of tar is (2,10),\n",
        "# tar[:, :-1] (2,9) the first token to 2 from the last. skip the last token. it's something the docoder read\n",
        "# and tar[:, 1:] from the second to the last. this is somthing we hope that decoder can generate.\n",
        "tar_inp = tar[:, :-1] # input of decoder.\n",
        "tar_real = tar[:, 1:] # it's the next token of tar_inp. tar[:, 0] vs. tar[:, 1]\n",
        "\n",
        "# combined mask for decoder to generate next work.\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar_inp)\n",
        "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# intialize the transformer\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "              input_vocab_size, output_vocab_size)\n",
        "\n",
        "# call the transformer\n",
        "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask,\n",
        "                      combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_inp:\", tar_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_real:\", tar_real)\n",
        "print(\"-\" * 20)\n",
        "print(\"predictions:\", predictions)\n",
        "\n",
        "#when decoder recieve first token from tar[:, 0] (<BOS> here), with the help of encoder,\n",
        "#the target of decoder is tar[:, 1]. (10 here)\n",
        "# the size of tar_real is (2,9) and the ouput size of prediction is (2,9,4107) where 4107 is the size of ch dictionary.\n",
        "# 2 examples, 9 next tokens (start from <BOS>), 4107 options in the ch dictionary for decoder."
      ],
      "metadata": {
        "id": "l1-vJi5ToQWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d4e748-bb4d-4ae7-fcd5-a7846e7a6b1c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_inp: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "tar_real: tf.Tensor(\n",
            "[[  10  241   86   27    3 4206    0    0    0]\n",
            " [ 165  489  398  191   14    7  560    3 4206]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "predictions: tf.Tensor(\n",
            "[[[ 0.05784188 -0.05961496  0.06972247 ...  0.01011086 -0.00407425\n",
            "   -0.00957866]\n",
            "  [ 0.05878117 -0.05927178  0.06763508 ...  0.01427912 -0.00535881\n",
            "   -0.00568688]\n",
            "  [ 0.05987471 -0.0344992   0.05116527 ...  0.01482514 -0.03040656\n",
            "    0.02629289]\n",
            "  ...\n",
            "  [ 0.05900498 -0.05729111  0.07182156 ...  0.00500571 -0.00761403\n",
            "   -0.00864795]\n",
            "  [ 0.05861768 -0.05855691  0.07032468 ...  0.0086512  -0.00593853\n",
            "   -0.008384  ]\n",
            "  [ 0.06415838 -0.04724629  0.06914022 ...  0.00327487 -0.02281512\n",
            "    0.0078424 ]]\n",
            "\n",
            " [[ 0.05816669 -0.05939595  0.06953594 ...  0.01051509 -0.00462713\n",
            "   -0.00873855]\n",
            "  [ 0.05976028 -0.05764984  0.06547698 ...  0.01711843 -0.00793421\n",
            "   -0.00098454]\n",
            "  [ 0.05905934 -0.03344881  0.0492615  ...  0.01602051 -0.03053627\n",
            "    0.02749891]\n",
            "  ...\n",
            "  [ 0.05916593 -0.05727348  0.07160346 ...  0.00552808 -0.00779664\n",
            "   -0.00814832]\n",
            "  [ 0.05902388 -0.05852826  0.06932256 ...  0.01076443 -0.00637499\n",
            "   -0.00666018]\n",
            "  [ 0.06359011 -0.04169448  0.06236696 ...  0.00784589 -0.02751018\n",
            "    0.01689621]]], shape=(2, 9, 4207), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training process\n",
        "1. Define loss function\n",
        "2."
      ],
      "metadata": {
        "id": "x7BviA9Gi2WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label\n",
        "real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)\n",
        "pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)\n",
        "loss_object(real, pred)"
      ],
      "metadata": {
        "id": "eIdl5qwsoVrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac52c27b-4071-4517-8337-f23ecd88c9ad"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.31326175, 0.31326175, 1.3132617 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"predictions:\", predictions)\n",
        "print(\"-\" * 20)\n",
        "print(tf.reduce_sum(predictions, axis=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66epy8FujW7X",
        "outputId": "02980989-25e0-4002-aa1e-0884cda0d0ea"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions: tf.Tensor(\n",
            "[[[ 0.05784188 -0.05961496  0.06972247 ...  0.01011086 -0.00407425\n",
            "   -0.00957866]\n",
            "  [ 0.05878117 -0.05927178  0.06763508 ...  0.01427912 -0.00535881\n",
            "   -0.00568688]\n",
            "  [ 0.05987471 -0.0344992   0.05116527 ...  0.01482514 -0.03040656\n",
            "    0.02629289]\n",
            "  ...\n",
            "  [ 0.05900498 -0.05729111  0.07182156 ...  0.00500571 -0.00761403\n",
            "   -0.00864795]\n",
            "  [ 0.05861768 -0.05855691  0.07032468 ...  0.0086512  -0.00593853\n",
            "   -0.008384  ]\n",
            "  [ 0.06415838 -0.04724629  0.06914022 ...  0.00327487 -0.02281512\n",
            "    0.0078424 ]]\n",
            "\n",
            " [[ 0.05816669 -0.05939595  0.06953594 ...  0.01051509 -0.00462713\n",
            "   -0.00873855]\n",
            "  [ 0.05976028 -0.05764984  0.06547698 ...  0.01711843 -0.00793421\n",
            "   -0.00098454]\n",
            "  [ 0.05905934 -0.03344881  0.0492615  ...  0.01602051 -0.03053627\n",
            "    0.02749891]\n",
            "  ...\n",
            "  [ 0.05916593 -0.05727348  0.07160346 ...  0.00552808 -0.00779664\n",
            "   -0.00814832]\n",
            "  [ 0.05902388 -0.05852826  0.06932256 ...  0.01076443 -0.00637499\n",
            "   -0.00666018]\n",
            "  [ 0.06359011 -0.04169448  0.06236696 ...  0.00784589 -0.02751018\n",
            "    0.01689621]]], shape=(2, 9, 4207), dtype=float32)\n",
            "--------------------\n",
            "tf.Tensor(\n",
            "[[ 0.14647758  0.431839    1.3791032  -0.03168643 -0.5214072  -0.25835988\n",
            "  -0.03814057  0.12057027  0.36724228]\n",
            " [ 0.18754545  0.68554926  1.4634585   0.59369886 -0.39648452 -0.29257286\n",
            "  -0.00203142  0.2580318   0.8184228 ]], shape=(2, 9), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "  # 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  # 照樣計算所有位置的 cross entropy 但不加總\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask  # 只計算非 <pad> 位置的損失\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "8HyD3HlYjPae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "metadata": {
        "id": "i4kQlJW4jSwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "dropout_rate = 0.1  # 預設值\n",
        "\n",
        "print(\"input_vocab_size:\", input_vocab_size)\n",
        "print(\"target_vocab_size:\", target_vocab_size)"
      ],
      "metadata": {
        "id": "JsCM_gk_je6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  # 論文預設 `warmup_steps` = 4000\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
        "# Adam opt. 的參數都跟論文相同\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "RKdLEXS0jhw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_models = [128, 256, 512]\n",
        "warmup_steps = [1000 * i for i in range(1, 4)]\n",
        "\n",
        "schedules = []\n",
        "labels = []\n",
        "colors = [\"blue\", \"red\", \"black\"]\n",
        "for d in d_models:\n",
        "  schedules += [CustomSchedule(d, s) for s in warmup_steps]\n",
        "  labels += [f\"d_model: {d}, warm: {s}\" for s in warmup_steps]\n",
        "\n",
        "for i, (schedule, label) in enumerate(zip(schedules, labels)):\n",
        "  plt.plot(schedule(tf.range(10000, dtype=tf.float32)),\n",
        "           label=label, color=colors[i // 3])\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "id": "fw6NHTQsj63O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
        "\n",
        "print(f\"\"\"這個 Transformer 有 {num_layers} 層 Encoder / Decoder layers\n",
        "d_model: {d_model}\n",
        "num_heads: {num_heads}\n",
        "dff: {dff}\n",
        "input_vocab_size: {input_vocab_size}\n",
        "target_vocab_size: {target_vocab_size}\n",
        "dropout_rate: {dropout_rate}\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "9hTSd191mz_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 方便比較不同實驗/ 不同超參數設定的結果\n",
        "# run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
        "# checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
        "# log_dir = os.path.join(log_dir, run_id)\n",
        "\n",
        "# # tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
        "# # 一般來說你會想存下模型以及 optimizer 的狀態\n",
        "# ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "#                            optimizer=optimizer)\n",
        "\n",
        "# # ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
        "# # 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
        "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# # 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "\n",
        "#   # 用來確認之前訓練多少 epochs 了\n",
        "#   last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
        "#   print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
        "# else:\n",
        "#   last_epoch = 0\n",
        "#   print(\"沒找到 checkpoint，從頭訓練。\")"
      ],
      "metadata": {
        "id": "XEF5u-CKnFjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 為 Transformer 的 Encoder / Decoder 準備遮罩\n",
        "def create_masks(inp, tar):\n",
        "  # 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2\n",
        "  # 關注 Encoder 輸出序列用的\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Decoder layer 的 MHA1 在做自注意力機制用的\n",
        "  # `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "5GgoC14Hm2Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
        "def train_step(inp, tar):\n",
        "  # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "\n",
        "  # 建立 3 個遮罩\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "  # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
        "    predictions, _ = transformer(inp, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "metadata": {
        "id": "0AJmK1QznJea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義我們要看幾遍數據集\n",
        "EPOCHS = 100\n",
        "last_epoch = 0\n",
        "print(f\"此超參數組合的 Transformer 已經訓練 {last_epoch} epochs。\")\n",
        "print(f\"剩餘 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
        "\n",
        "\n",
        "# 用來寫資訊到 TensorBoard，非必要但十分推薦\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs\n",
        "for epoch in range(last_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # 重置紀錄 TensorBoard 的 metrics\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集\n",
        "  for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
        "\n",
        "    # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss\n",
        "    train_step(inp, tar)\n",
        "\n",
        "  # 每個 epoch 完成就存一次檔\n",
        "  # if (epoch + 1) % 1 == 0:\n",
        "  #   ckpt_save_path = ckpt_manager.save()\n",
        "  #   print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "  #                                                        ckpt_save_path))\n",
        "\n",
        "  # 將 loss 以及 accuracy 寫到 TensorBoard 上\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
        "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                                train_loss.result(),\n",
        "                                                train_accuracy.result()))\n",
        "  print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
        "\n",
        "\n",
        "# no trainable_vars in transformer and related layers. trainable_vars must be inherited through keras.layers or keras.model"
      ],
      "metadata": {
        "id": "HVLXkMpYnTsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {your_log_dir}"
      ],
      "metadata": {
        "id": "i7KpoeJzplSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict\n",
        "def evaluate(inp_sentence):\n",
        "\n",
        "  # 準備英文句子前後會加上的 <start>, <end>\n",
        "  start_token = [subword_encoder_en.vocab_size]\n",
        "  end_token = [subword_encoder_en.vocab_size + 1]\n",
        "\n",
        "  # inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列\n",
        "  # 並在前後加上 BOS / EOS\n",
        "  inp_sentence = start_token + subword_encoder_en.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "\n",
        "  # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
        "  # 是一個只包含一個中文 <start> token 的序列\n",
        "  decoder_input = [subword_encoder_zh.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
        "\n",
        "  # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 每多一個生成的字就得產生新的遮罩\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "\n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input,\n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "\n",
        "\n",
        "    # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
        "    predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
        "    if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "    #將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
        "    # 下個中文字的時候關注到最新的 `predicted_id`\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "id": "fSE6DHdlscTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 要被翻譯的英文句子\n",
        "sentence = \"China, India, and others have enjoyed continuing economic growth.\"\n",
        "\n",
        "# 取得預測的中文索引序列\n",
        "predicted_seq, _ = evaluate(sentence)\n",
        "\n",
        "# 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
        "target_vocab_size = subword_encoder_zh.vocab_size\n",
        "predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
        "predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
        "\n",
        "print(\"sentence:\", sentence)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_seq:\", predicted_seq)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_sentence:\", predicted_sentence)"
      ],
      "metadata": {
        "id": "2kbe5xcesdyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "id": "Td18FI8xtBP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_seq, attention_weights = evaluate(sentence)\n",
        "\n",
        "# 在這邊我們自動選擇最後一個 Decoder layer 的 MHA 2，也就是 Decoder 關注 Encoder 的 MHA\n",
        "layer_name = f\"decoder_layer{num_layers}_block2\"\n",
        "\n",
        "print(\"sentence:\", sentence)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_seq:\", predicted_seq)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights.keys():\")\n",
        "for layer_name, attn in attention_weights.items():\n",
        "  print(f\"{layer_name}.shape: {attn.shape}\")\n",
        "print(\"-\" * 20)\n",
        "print(\"layer_name:\", layer_name)"
      ],
      "metadata": {
        "id": "W3sAberwsltO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-wqy-zenhei\n",
        "!fc-cache -fv"
      ],
      "metadata": {
        "id": "53804PzZ5haC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "# 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文\n",
        "zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc')\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "# 這個函式將英 -> 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果\n",
        "def plot_attention_weights(attention_weights, sentence, predicted_seq, layer_name, max_len_tar=None):\n",
        "    fig = plt.figure(figsize=(17, 7))\n",
        "\n",
        "    sentence = subword_encoder_en.encode(sentence)\n",
        "\n",
        "    if max_len_tar:\n",
        "        predicted_seq = predicted_seq[:max_len_tar]\n",
        "    else:\n",
        "        max_len_tar = len(predicted_seq)\n",
        "\n",
        "    attention_weights = tf.squeeze(attention_weights[layer_name], axis=0)\n",
        "\n",
        "    for head in range(attention_weights.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head + 1)\n",
        "\n",
        "        attn_map = np.transpose(attention_weights[head][:max_len_tar, :])\n",
        "        ax.matshow(attn_map, cmap='viridis')\n",
        "\n",
        "        fontdict = {\"fontproperties\": zhfont}\n",
        "\n",
        "        ax.set_xticks(range(max_len_tar))\n",
        "        ax.set_xlim(-0.5, max_len_tar - 1.5)\n",
        "\n",
        "        # Use a consistent list of tick labels for the y-axis\n",
        "        y_tick_labels = ['<start>'] + [subword_encoder_en.decode([i]) for i in sentence] + ['<end>']\n",
        "        ax.set_yticks(range(len(y_tick_labels)))\n",
        "        ax.set_yticklabels(y_tick_labels, fontdict=fontdict)\n",
        "\n",
        "        ax.set_xlabel('Head {}'.format(head + 1))\n",
        "        ax.tick_params(axis=\"x\", labelsize=12)\n",
        "        ax.tick_params(axis=\"y\", labelsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "Eb-1G6QRspig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention_weights(attention_weights, sentence,\n",
        "                       predicted_seq, layer_name, max_len_tar=18)"
      ],
      "metadata": {
        "id": "TwPHJErrsr07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. review positional encoding\n",
        "3. input of transformer + padding\n",
        "4. How to train it? 只計算pad?\n",
        "6. learning rate schedule\n",
        "7. check point\n",
        "9. How to do tensorboard?\n",
        "\n",
        "Have no idea whats wrong with training step?\n",
        "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit retwrite it."
      ],
      "metadata": {
        "id": "VadCYB-ejCe1"
      }
    }
  ]
}